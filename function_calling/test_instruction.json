[
  {
    "instruction": "Get the overview of the data including number of rows, columns, and basic statistics.",
    "function_call": {
      "name": "data_description",
      "arguments": {}
    }
  },
  {
    "instruction": "Display the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete the column named 'unnecessary_column' from the dataset.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_column"
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the data into 80% training and 20% testing sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode categorical column 'category' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'gender' column.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "gender"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Draw a correlation matrix for all features.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Normalize the 'height' and 'weight' columns to range between 0 and 1.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "height,weight"
      }
    }
  },
  {
    "instruction": "Delete rows indexed at 0, 10, and 20.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          0,
          10,
          20
        ]
      }
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) for classification.",
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a linear regression model.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Create a correlation matrix plot.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a neural network classifier.",
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an XGBoost classifier.",
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Specify the task as classification with 'target' as the target column.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target"
      }
    }
  },
  {
    "instruction": "Select the top 5 features based on mutual information.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Impute missing values in the dataset using the mean strategy.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce dimensionality to 2 components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data into training and testing sets with a 20% test ratio.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureX' and 'featureY'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureX','featureY')"
      }
    }
  },
  {
    "instruction": "Evaluate the logistic regression model on train and test data.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the SVM model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svc",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Generate a confusion matrix plot for the decision tree classifier.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the random forest model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Detect and mark outliers using the IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr"
      }
    }
  },
  {
    "instruction": "Load the saved model from 'saved_model.pkl'.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "saved_model.pkl"
      }
    }
  },
  {
    "instruction": "Check for class imbalance in the classification dataset.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {}
    }
  },
  {
    "instruction": "Scale features 'featureA' and 'featureB' using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Treat detected outliers by replacing them with the median.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "median",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Sample 80% of the dataset for downsampling.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "downsampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'feature1' and 'feature2' to create a new feature 'featureAB'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "instruction": "Iteratively eliminate features using backward elimination.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "instruction": "Forecast the next 30 days using an ARIMA model.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "30"
      }
    }
  },
  {
    "instruction": "Interpret the predictions of the logistic regression model for instance '123'.",
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "logistic_regression",
        "instance_id": "123"
      }
    }
  },
  {
    "instruction": "Anonymize personal data with k-anonymity.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize 'featureZ' into 5 equal width bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "featureZ"
      }
    }
  },
  {
    "instruction": "Augment the dataset by rotating images 10 degrees.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "rotation",
        "angle": "10"
      }
    }
  },
  {
    "instruction": "Decompose time series into trend, seasonality, and residuals with an additive model.",
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "additive"
      }
    }
  },
  {
    "instruction": "Stack models 'model1' and 'model2' with a logistic regression meta-model.",
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": "['model1', 'model2']",
        "meta_model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Enrich the dataset by merging with external data from 'external_data.csv'.",
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "external_data.csv"
      }
    }
  },
  {
    "instruction": "Create a preprocessing pipeline with steps 'data_description' and 'standardization'.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "['data_description', 'standardization']"
      }
    }
  },
  {
    "instruction": "Train a K-Nearest Neighbors classifier with 5 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "5"
      }
    }
  },
  {
    "instruction": "Show the first 15 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "15"
      }
    }
  },
  {
    "instruction": "Delete columns 'columnX' and 'columnY'.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": [
          "columnX",
          "columnY"
        ]
      }
    }
  },
  {
    "instruction": "Standardize columns 'age' and 'education_years'.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,education_years"
      }
    }
  },
  {
    "instruction": "Split the dataset into 70% training and 30% testing sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3"
      }
    }
  },
  {
    "instruction": "Encode 'category_column' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category_column"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'gender_column'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "gender_column"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model with L2 regularization.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Visualize the dataset's correlation matrix.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Normalize 'feature1' and 'feature2' to the range [0,1].",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Handle missing values in 'income' column by imputing the mean.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean",
        "columns": "income"
      }
    }
  },
  {
    "instruction": "Reduce data dimensions using PCA to 3 components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "3"
      }
    }
  },
  {
    "instruction": "Split time series data with a test size of 0.15.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.15"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'featureA' and 'featureB'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "featureA,featureB",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureC' and 'featureD'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "['featureC,featureD']"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of the random forest model on train/test splits.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Perform 10-fold cross-validation on the linear regression model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "linear_regression",
        "folds": "10"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for the decision tree classifier.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract the most important features from the trained model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "instruction": "Detect outliers using Z-score with a threshold of 3.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "zscore",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Load the 'best_model.sav' from disk.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "best_model.sav"
      }
    }
  },
  {
    "instruction": "Check for class balance in the 'classification_set'.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {}
    }
  },
  {
    "instruction": "Scale 'age' and 'income' columns using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Treat detected outliers by capping values at 3 standard deviations.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Randomly sample 20% of the dataset.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.2"
      }
    }
  },
  {
    "instruction": "Combine 'featureX' and 'featureY' into a new feature 'XY_combination'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "featureX*featureY"
      }
    }
  },
  {
    "instruction": "Eliminate features using forward selection until 7 remain.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "forward_selection",
        "scoring": "roc_auc",
        "num_features": "7"
      }
    }
  },
  {
    "instruction": "Forecast the next quarter's sales using a time series model.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "sarima",
        "horizon": "3 months"
      }
    }
  },
  {
    "instruction": "Interpret the predictions of the random forest model for a specific instance.",
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "random_forest_classifier",
        "instance_id": "sample_instance"
      }
    }
  },
  {
    "instruction": "Anonymize personal identification fields.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Discretize 'featureZ' into 10 bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "10",
        "columns": "featureZ"
      }
    }
  },
  {
    "instruction": "Augment image dataset by flipping horizontally.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "horizontal_flip"
      }
    }
  },
  {
    "instruction": "Decompose time series into components with a multiplicative model.",
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "multiplicative"
      }
    }
  },
  {
    "instruction": "Stack models 'lr_model', 'rf_model' with a logistic regression meta-model.",
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": [
          "lr_model",
          "rf_model"
        ],
        "meta_model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Enhance the dataset by appending data from 'external_dataset.csv'.",
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "external_dataset.csv"
      }
    }
  },
  {
    "instruction": "Create a preprocessing pipeline with 'standardization' and 'PCA' steps.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": [
          "standardization",
          "principal_component_analysis"
        ]
      }
    }
  },
  {
    "instruction": "Train a K-Nearest Neighbors classifier with 7 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "7"
      }
    }
  },
  {
    "instruction": "Calculate the recall score for the 'svm_model'.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "svm_model"
      }
    }
  },
  {
    "instruction": "Calculate the precision score for the 'logistic_regression_model'.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "logistic_regression_model"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared error for the 'regression_model'.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "regression_model"
      }
    }
  },
  {
    "instruction": "Calculate R-squared for the 'linear_regression_model'.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "linear_regression_model"
      }
    }
  },
  {
    "instruction": "Calculate the mean absolute error for the 'forecast_model'.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "forecast_model"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'featureA' and 'featureB' in the 'gb_model'.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "gb_model",
        "features": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Perform exponential smoothing on 'sales_data' with a smoothing factor of 0.3.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "smoothing_factor": "0.3",
        "data": "sales_data"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Mixture Model with 4 clusters.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Use Stochastic Gradient Descent for optimization with a learning rate of 0.01.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ Adam optimizer with a learning rate of 0.001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Use RMSprop optimizer with a rho of 0.9.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Apply Adagrad optimizer with a learning rate of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Use Nesterov's Accelerated Gradient with 1000 iterations.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Employ basic Gradient Descent with a learning rate of 0.005.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.005"
      }
    }
  },
  {
    "instruction": "Display the first 20 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "20"
      }
    }
  },
  {
    "instruction": "Delete the 'unnecessary_col' column.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_col"
      }
    }
  },
  {
    "instruction": "Standardize the 'features_to_normalize' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "features_to_normalize"
      }
    }
  },
  {
    "instruction": "Split data into training and testing sets with a 70/30 split.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3"
      }
    }
  },
  {
    "instruction": "Encode 'category_column' ordinally.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category_column"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'categorical_features'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categorical_features"
      }
    }
  },
  {
    "instruction": "Train a simple logistic regression model.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Visualize the data's correlation matrix.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Normalize 'numeric_features' to range [0,1].",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "numeric_features"
      }
    }
  },
  {
    "instruction": "Impute missing values in 'age' column with the mean.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean",
        "columns": "age"
      }
    }
  },
  {
    "instruction": "Reduce data dimensions using PCA to 2 dimensions.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data respecting order with a 20% test set.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "['featureA,featureB']"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of the trained 'knn_model'.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "knn_model"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on 'svm_model'.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svm_model",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for 'classifier_model'.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Identify feature importances in 'rf_model'.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "rf_model"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'data' using IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr"
      }
    }
  },
  {
    "instruction": "Load the saved 'best_model' from a file.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "best_model"
      }
    }
  },
  {
    "instruction": "Check class balance in 'target_column'.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {
        "column": "target_column"
      }
    }
  },
  {
    "instruction": "Min-Max scale 'to_scale_features'.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "to_scale_features"
      }
    }
  },
  {
    "instruction": "Treat detected outliers in 'income' by setting to median.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "median",
        "columns": "income"
      }
    }
  },
  {
    "instruction": "Sample 80% of data randomly.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'featureX' and 'featureY' to form 'XY_combo'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "featureX+featureY"
      }
    }
  },
  {
    "instruction": "Sequentially select features for 'classifier_task'.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "forward_selection",
        "task": "classifier_task"
      }
    }
  },
  {
    "instruction": "Forecast future values with 'sarima_model'.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "sarima_model"
      }
    }
  },
  {
    "instruction": "Interpret model 'tree_model' predictions.",
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "tree_model"
      }
    }
  },
  {
    "instruction": "Anonymize sensitive data.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize 'continuous_feature' into 5 bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "continuous_feature"
      }
    }
  },
  {
    "instruction": "Horizontally flip images for augmentation.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "horizontal_flip"
      }
    }
  },
  {
    "instruction": "Decompose time series with a multiplicative model.",
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "multiplicative"
      }
    }
  },
  {
    "instruction": "Stack models 'model1', 'model2' with 'stacked_model'.",
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": [
          "model1",
          "model2"
        ],
        "meta_model": "stacked_model"
      }
    }
  },
  {
    "instruction": "Enrich dataset with 'external_database'.",
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "external_database"
      }
    }
  },
  {
    "instruction": "Create a preprocessing pipeline with 'standardization' and 'PCA' steps.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": [
          "standardization",
          "principal_component_analysis"
        ]
      }
    }
  },
  {
    "instruction": "Train a K-NN classifier with 5 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "5"
      }
    }
  },
  {
    "instruction": "Calculate recall score for 'classification_model'.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "classification_model"
      }
    }
  },
  {
    "instruction": "Calculate precision score for 'model_precision_test'.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "model_precision_test"
      }
    }
  },
  {
    "instruction": "Calculate MSE for 'regression_fit'.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "regression_fit"
      }
    }
  },
  {
    "instruction": "Calculate R-squared for 'regression_model_test'.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "regression_model_test"
      }
    }
  },
  {
    "instruction": "Calculate MAE for 'forecasting_model'.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "forecasting_model"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'feature_impact' in 'gb_model'.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "gb_model",
        "features": "feature_impact"
      }
    }
  },
  {
    "instruction": "Perform exponential smoothing on 'time_series_data'.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "data": "time_series_data"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Mixture Model with 3 clusters.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "3"
      }
    }
  },
  {
    "instruction": "Use SGD for optimization with momentum.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "momentum": "0.9"
      }
    }
  },
  {
    "instruction": "Apply Adam optimization with a beta1 of 0.9.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "beta_1": "0.9"
      }
    }
  },
  {
    "instruction": "Use RMSprop with a learning rate of 0.001.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Apply Adagrad with initial accumulator value of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "initial_accumulator_value": "0.1"
      }
    }
  },
  {
    "instruction": "Use Nesterov's momentum with a learning rate of 0.01.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ basic Gradient Descent with a batch size of 32.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "batch_size": "32"
      }
    }
  },
  {
    "instruction": "Display the first 25 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "25"
      }
    }
  },
  {
    "instruction": "Delete 'column_to_remove' column.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "column_to_remove"
      }
    }
  },
  {
    "instruction": "Standardize columns 'to_standardize' with Z-score normalization.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "to_standardize"
      }
    }
  },
  {
    "instruction": "Split dataset into 60% train and 40% test sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.4"
      }
    }
  },
  {
    "instruction": "Encode 'categorical_column' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "categorical_column"
      }
    }
  },
  {
    "instruction": "One-hot encode 'categorical_features'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categorical_features"
      }
    }
  },
  {
    "instruction": "Train a simple linear regression model.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Visualize the data correlation heatmap.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Normalize 'numerical_features' to [0, 1] range.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "numerical_features"
      }
    }
  },
  {
    "instruction": "Impute missing numerical values using mean.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean",
        "columns": "numerical_columns"
      }
    }
  },
  {
    "instruction": "Reduce dimensionality to 3 components using PCA.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "3"
      }
    }
  },
  {
    "instruction": "Time series split with a 12-month test set.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "12"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "['featureA,featureB']"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of 'svm_classifier' on test data.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "svm_classifier"
      }
    }
  },
  {
    "instruction": "Cross-validate 'random_forest' with 10 folds.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "random_forest",
        "folds": "10"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for 'logistic_regression_model'.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "logistic_regression_model"
      }
    }
  },
  {
    "instruction": "Identify important features in 'rf_model'.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "rf_model"
      }
    }
  },
  {
    "instruction": "Detect and handle outliers in 'feature_column' with IQR.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "columns": "feature_column"
      }
    }
  },
  {
    "instruction": "Load the saved 'model_save_path' model.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "model_save_path"
      }
    }
  },
  {
    "instruction": "Check the class balance in 'label_column'.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {
        "column": "label_column"
      }
    }
  },
  {
    "instruction": "Scale 'to_scale' columns using Min-Max scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "to_scale"
      }
    }
  },
  {
    "instruction": "Treat outliers in 'salary' by capping at 3 standard deviations.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "3",
        "columns": "salary"
      }
    }
  },
  {
    "instruction": "Randomly sample 50% of the dataset.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.5"
      }
    }
  },
  {
    "instruction": "Combine 'featureX' and 'featureY' to form 'XY_feature'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "featureX+featureY"
      }
    }
  },
  {
    "instruction": "Sequentially eliminate features for 'classifier_task'.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "task": "classifier_task"
      }
    }
  },
  {
    "instruction": "Forecast using 'forecast_model' for the next 6 periods.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "forecast_model",
        "horizon": "6"
      }
    }
  },
  {
    "instruction": "Visualize SHAP values for 'tree_model' predictions.",
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "tree_model"
      }
    }
  },
  {
    "instruction": "Anonymize sensitive 'personal_data' fields.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity",
        "columns": "personal_data"
      }
    }
  },
  {
    "instruction": "Discretize 'age' into 5 equal intervals.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "age"
      }
    }
  },
  {
    "instruction": "Apply horizontal flips for image augmentation.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "horizontal_flip"
      }
    }
  },
  {
    "instruction": "Decompose time series with multiplicative seasonality.",
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "multiplicative"
      }
    }
  },
  {
    "instruction": "Stack 'base_models' into an ensemble.",
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": "base_models",
        "meta_model": "stacked_model"
      }
    }
  },
  {
    "instruction": "Enrich data with 'external_data_source'.",
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "external_data_source"
      }
    }
  },
  {
    "instruction": "Create a preprocessing pipeline with 'standardization' and 'PCA' steps.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": [
          "standardization",
          "principal_component_analysis"
        ]
      }
    }
  },
  {
    "instruction": "Train 'knn_classifier' with 7 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "7"
      }
    }
  },
  {
    "instruction": "Calculate recall score for 'classifier_performance'.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "classifier_performance"
      }
    }
  },
  {
    "instruction": "Calculate precision score for 'precision_check_model'.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "precision_check_model"
      }
    }
  },
  {
    "instruction": "Calculate MSE for 'regression_performance'.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "regression_performance"
      }
    }
  },
  {
    "instruction": "Calculate R-squared for 'regression_model'.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "regression_model"
      }
    }
  },
  {
    "instruction": "Calculate MAE for 'forecast_model_performance'.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "forecast_model_performance"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'feature_of_interest' in 'gb_model'.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "gb_model",
        "features": "feature_of_interest"
      }
    }
  },
  {
    "instruction": "Perform exponential smoothing on 'time_series_data'.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "data": "time_series_data"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Mixture Model with 4 components.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Use SGD with a learning rate of 0.001.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Apply Adam with a learning rate of 0.0001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.0001"
      }
    }
  },
  {
    "instruction": "Use RMSprop with a decay rate of 0.9.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "decay": "0.9"
      }
    }
  },
  {
    "instruction": "Apply Adagrad with a learning rate of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Use Nesterov's momentum with a learning rate of 0.01.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ basic Gradient Descent with a learning rate of 0.01.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Create a feature 'age_group' by binning 'age' into decades.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "age//10"
      }
    }
  },
  {
    "instruction": "Save the trained 'classifier_model' to 'classifier.pkl'.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "filename": "classifier.pkl",
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Calculate feature importances using permutation feature importance.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "method": "permutation",
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Perform stratified sampling to maintain class balance.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "stratified",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Plot learning curves for 'svm_model'.",
    "function_call": {
      "name": "learning_curve_plot",
      "arguments": {
        "model": "svm_model"
      }
    }
  },
  {
    "instruction": "Calculate F1 score for 'classification_model'.",
    "function_call": {
      "name": "f1_score",
      "arguments": {
        "model": "classification_model"
      }
    }
  },
  {
    "instruction": "Visualize feature contributions for 'decision_tree' using SHAP.",
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "decision_tree"
      }
    }
  },
  {
    "instruction": "Detect and remove collinear features.",
    "function_call": {
      "name": "remove_collinear_features",
      "arguments": {
        "threshold": "0.8"
      }
    }
  },
  {
    "instruction": "Scale 'numeric_features' using RobustScaler.",
    "function_call": {
      "name": "feature_scaling_robust",
      "arguments": {
        "columns": "numeric_features"
      }
    }
  },
  {
    "instruction": "Detect and replace outliers in 'salary' column using IQR.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "columns": "salary"
      }
    }
  },
  {
    "instruction": "Apply label encoding to 'categorical_target'.",
    "function_call": {
      "name": "label_encoding",
      "arguments": {
        "columns": "categorical_target"
      }
    }
  },
  {
    "instruction": "Evaluate model stability with bootstrapping.",
    "function_call": {
      "name": "bootstrap_model_evaluation",
      "arguments": {
        "model": "stable_model",
        "iterations": "100"
      }
    }
  },
  {
    "instruction": "Train a deep neural network with 3 hidden layers.",
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {
        "hidden_layers": "[64, 32, 16]"
      }
    }
  },
  {
    "instruction": "Perform principal component analysis with 2 components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Evaluate model performance using cross-entropy loss.",
    "function_call": {
      "name": "evaluate_model",
      "arguments": {
        "metric": "cross_entropy",
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Apply PCA for dimensionality reduction before clustering.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2",
        "before_clustering": true
      }
    }
  },
  {
    "instruction": "Train a simple linear regression for predicting 'price'.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {
        "target": "price"
      }
    }
  },
  {
    "instruction": "Perform grid search for hyperparameter tuning on 'svm_model'.",
    "function_call": {
      "name": "grid_search_cv",
      "arguments": {
        "model": "svm_model",
        "params": {
          "C": [
            0.1,
            1,
            10
          ]
        }
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix for feature exploration.",
    "function_call": {
      "name": "scatter_matrix",
      "arguments": {
        "features": "[feature1, feature2, feature3]"
      }
    }
  },
  {
    "instruction": "Use Lasso regression for feature selection.",
    "function_call": {
      "name": "feature_selection_lasso",
      "arguments": {
        "alpha": "0.1"
      }
    }
  },
  {
    "instruction": "Get the overview of the data.",
    "function_call": {
      "name": "data_description"
    }
  },
  {
    "instruction": "Show the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete the column named 'id'.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "id"
      }
    }
  },
  {
    "instruction": "Delete rows at indices 0, 1, and 2.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          0,
          1,
          2
        ]
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the dataset into 70% train and 30% test datasets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3"
      }
    }
  },
  {
    "instruction": "Encode the 'category' column ordinally.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'gender' and 'location'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "gender,location"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression"
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) model.",
    "function_call": {
      "name": "svc"
    }
  },
  {
    "instruction": "Train a linear regression model.",
    "function_call": {
      "name": "linear_regression"
    }
  },
  {
    "instruction": "Draw a correlation matrix for all features.",
    "function_call": {
      "name": "correlation_matrix"
    }
  },
  {
    "instruction": "Train a neural network for classification.",
    "function_call": {
      "name": "neural_network_classifier"
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier"
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier"
    }
  },
  {
    "instruction": "Train an XGBoost classifier.",
    "function_call": {
      "name": "xgb_classifier"
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier"
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier"
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier"
    }
  },
  {
    "instruction": "Extract task and target from the dataset as a classification problem.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Select top 5 features using mutual information criterion.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Normalize the 'height' and 'weight' columns.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "height,weight"
      }
    }
  },
  {
    "instruction": "Impute missing values in the dataset using mean strategy.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce dimensions to 2.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data with a test size of 20%.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create polynomial features from 'feature1' and 'feature2' up to degree 2.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureA','featureB')"
      }
    }
  },
  {
    "instruction": "Evaluate the accuracy of the trained logistic regression model on train and test sets.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression_model"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the decision tree model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "decision_tree",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Generate a confusion matrix plot for the random forest classifier.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the trained gradient boosting model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "gradient_boosting_model"
      }
    }
  },
  {
    "instruction": "Detect and remove outliers using IQR method with a threshold of 1.5.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Load the saved logistic regression model from 'model.sav'.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "model.sav"
      }
    }
  },
  {
    "instruction": "Check for class balance in the 'target' column.",
    "function_call": {
      "name": "data_balance_check"
    }
  },
  {
    "instruction": "Scale 'feature1' and 'feature2' using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Treat detected outliers by replacing them with the median.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "replacement",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Sample 80% of the dataset for downsampling.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "downsampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'feature1' and 'feature2' to create a new feature 'featureAB'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "instruction": "Eliminate features iteratively using backward elimination with 'accuracy' as the metric.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "instruction": "Forecast the next 12 months of sales using ARIMA.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "12"
      }
    }
  },
  {
    "instruction": "Analyze the model complexity of the random forest model.",
    "function_call": {
      "name": "model_complexity_analysis"
    }
  },
  {
    "instruction": "Apply logarithmic transformation to 'price' column.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "price"
      }
    }
  },
  {
    "instruction": "Transform text data in 'review' column with TF-IDF.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000"
      }
    }
  },
  {
    "instruction": "Split the dataset into 5 folds for cross-validation.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Optimize hyperparameters of the SVM model using grid search.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "svm",
        "param_grid": {
          "C": [
            0.1,
            1,
            10
          ],
          "kernel": [
            "linear",
            "rbf"
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate SHAP values for the trained neural network model.",
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "neural_network_model"
      }
    }
  },
  {
    "instruction": "Plot the calibration curve for the logistic regression model.",
    "function_call": {
      "name": "model_calibration_plot",
      "arguments": {
        "model": "logistic_regression",
        "bins": "10"
      }
    }
  },
  {
    "instruction": "Plot the precision-recall curve for the random forest model.",
    "function_call": {
      "name": "model_evaluation_pr_curve",
      "arguments": {
        "model": "random_forest"
      }
    }
  },
  {
    "instruction": "Create a lift chart for the decision tree classifier.",
    "function_call": {
      "name": "model_evaluation_lift_chart",
      "arguments": {
        "model": "decision_tree",
        "bins": "5"
      }
    }
  },
  {
    "instruction": "Calculate recall score for the linear regression model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the precision score for the SVM model.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared error for the linear regression predictions.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the R-squared score for the random forest regression.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "random_forest_regression"
      }
    }
  },
  {
    "instruction": "Calculate the mean absolute error for the gradient boosting model.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "gradient_boosting_regression"
      }
    }
  },
  {
    "instruction": "Analyze residuals of the linear regression model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression",
        "predictions": "predicted_values",
        "actuals": "actual_values"
      }
    }
  },
  {
    "instruction": "Calculate prediction intervals for the elastic net regression at 95% confidence.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "elastic_net",
        "data": "test_data",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize the regression coefficients for the ridge regression model.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "ridge_regression"
      }
    }
  },
  {
    "instruction": "Assess multicollinearity in the dataset using VIF.",
    "function_call": {
      "name": "regression_multicollinearity_vif",
      "arguments": {
        "data": "regression_data"
      }
    }
  },
  {
    "instruction": "Train a polynomial regression model with degree 3.",
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "3"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'featureX' and 'featureY' on the random forest model.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "random_forest",
        "features": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Forecast sales with exponential smoothing, considering additive trend and seasonal effects.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "add",
        "damped": false
      }
    }
  },
  {
    "instruction": "Train a multiple linear regression model with 'featureA', 'featureB', and 'featureC'.",
    "function_call": {
      "name": "multiple_linear_regression",
      "arguments": {
        "predictors": "featureA,featureB,featureC"
      }
    }
  },
  {
    "instruction": "Train a Naive Bayes classifier with a Gaussian distribution.",
    "function_call": {
      "name": "naive_bayes_classifier",
      "arguments": {
        "algo": "gaussian"
      }
    }
  },
  {
    "instruction": "Cluster the data using spectral clustering with 3 clusters.",
    "function_call": {
      "name": "spectral_clustering",
      "arguments": {
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Fit a Gaussian Mixture Model with 4 components.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Perform clustering with a random forest, aiming for 5 clusters.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "5"
      }
    }
  },
  {
    "instruction": "Combine predictions of logistic regression and decision tree using hard voting.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "logistic_regression,decision_tree",
        "voting": "hard"
      }
    }
  },
  {
    "instruction": "Use SGD optimizer with a learning rate of 0.01 for model training.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "0.01",
        "loss": "hinge"
      }
    }
  },
  {
    "instruction": "Optimize model with the Adam optimizer and a learning rate of 0.001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Apply RMSprop optimization with a rho of 0.9.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Use Adagrad with a learning rate of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Optimize with Nesterov momentum with a learning rate of 0.05.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.05"
      }
    }
  },
  {
    "instruction": "Employ LBFGS optimizer for model fitting.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Standardize the entire dataset.",
    "function_call": {
      "name": "standardization"
    }
  },
  {
    "instruction": "Describe the data types and missing values in the dataset.",
    "function_call": {
      "name": "data_description"
    }
  },
  {
    "instruction": "Show the last 20 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "-20"
      }
    }
  },
  {
    "instruction": "Delete columns 'unnecessary_col1' and 'unnecessary_col2'.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_col1,unnecessary_col2"
      }
    }
  },
  {
    "instruction": "Delete rows with indices from 50 to 60.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          50,
          60
        ]
      }
    }
  },
  {
    "instruction": "Standardize columns 'feature1', 'feature2', and 'feature3'.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "feature1,feature2,feature3"
      }
    }
  },
  {
    "instruction": "Split the dataset into 80% training and 20% testing sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode categorical column 'category_col' ordinally.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category_col"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'status' and 'location' columns.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "status,location"
      }
    }
  },
  {
    "instruction": "Train a K-Nearest Neighbors classifier with 5 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "5"
      }
    }
  },
  {
    "instruction": "Evaluate the F1 score of the trained random forest classifier.",
    "function_call": {
      "name": "model_evaluation_f1_score",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Visualize feature importances for the XGBoost model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "xgb_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'featureX' using Z-score with a threshold of 3.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "zscore",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Save the trained model as 'my_model.pkl'.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "filename": "my_model.pkl",
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Create a boxplot for the 'income' feature.",
    "function_call": {
      "name": "data_visualization_boxplot",
      "arguments": {
        "feature": "income"
      }
    }
  },
  {
    "instruction": "Plot a scatter matrix for feature exploration.",
    "function_call": {
      "name": "data_visualization_scatter_matrix",
      "arguments": {
        "features": "feature1,feature2,feature3"
      }
    }
  },
  {
    "instruction": "Calculate the AUC-ROC score for the logistic regression model.",
    "function_call": {
      "name": "model_evaluation_auc_roc",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Apply k-anonymity to protect sensitive data.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize the 'age' column into 5 equal-width bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "columns": "age",
        "bins": "5"
      }
    }
  },
  {
    "instruction": "Create a pipeline combining standardization and PCA.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "['standardization', 'principal_component_analysis']"
      }
    }
  },
  {
    "instruction": "Evaluate the model using the area under the precision-recall curve.",
    "function_call": {
      "name": "model_evaluation_average_precision",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Plot a learning curve for the support vector machine model.",
    "function_call": {
      "name": "model_learning_curve",
      "arguments": {
        "model": "svc",
        "train_sizes": "[0.1, 0.5, 0.8]"
      }
    }
  },
  {
    "instruction": "Train an XGBoost regressor for predicting 'target_value'.",
    "function_call": {
      "name": "xgb_regressor",
      "arguments": {
        "objective": "reg:squarederror"
      }
    }
  },
  {
    "instruction": "Create a time series plot for the 'sales' data over the past year.",
    "function_call": {
      "name": "time_series_plot",
      "arguments": {
        "feature": "sales",
        "time_column": "date"
      }
    }
  },
  {
    "instruction": "Calculate the root mean squared log error for the regression model.",
    "function_call": {
      "name": "rmse_log",
      "arguments": {
        "model": "regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Perform a hypothesis test (t-test) on 'featureA' to check significance.",
    "function_call": {
      "name": "statistical_test_ttest",
      "arguments": {
        "feature": "featureA"
      }
    }
  },
  {
    "instruction": "Analyze feature correlations and visualize with a heatmap.",
    "function_call": {
      "name": "feature_correlation_heatmap"
    }
  },
  {
    "instruction": "Implement K-means clustering with 3 clusters.",
    "function_call": {
      "name": "kmeans",
      "arguments": {
        "clusters": "3"
      }
    }
  },
  {
    "instruction": "Perform DBSCAN clustering with an epsilon of 0.3 and minimum 5 samples.",
    "function_call": {
      "name": "dbscan",
      "arguments": {
        "eps": "0.3",
        "min_samples": "5"
      }
    }
  },
  {
    "instruction": "Apply Min-Max scaling to 'featureA' and 'featureB'.",
    "function_call": {
      "name": "data_transformation_minmax",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Generate a histogram for the 'age' feature with 10 bins.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age",
        "bins": "10"
      }
    }
  },
  {
    "instruction": "Create a pairplot for 'feature1', 'feature2', and 'feature3' with hue 'category'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Calculate the F1 micro score for the ensemble voting classifier.",
    "function_call": {
      "name": "model_evaluation_f1_score",
      "arguments": {
        "model": "ensemble_voting_classifier",
        "average": "micro"
      }
    }
  },
  {
    "instruction": "Visualize feature importances using a bar chart for the decision tree model.",
    "function_call": {
      "name": "feature_importance_bar_chart",
      "arguments": {
        "model": "decision_tree"
      }
    }
  },
  {
    "instruction": "Use Lasso regression with an alpha of 0.1.",
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.1"
      }
    }
  },
  {
    "instruction": "Train a Ridge regression model with an alpha of 1.0.",
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "1.0"
      }
    }
  },
  {
    "instruction": "Apply Elastic Net regression with an alpha of 0.5 and l1 ratio of 0.7.",
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.5",
        "l1_ratio": "0.7"
      }
    }
  },
  {
    "instruction": "Perform Grid Search for hyperparameter tuning on the SVM model.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "svc",
        "param_grid": {
          "C": [
            0.1,
            1,
            10
          ],
          "kernel": [
            "linear",
            "rbf"
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate the mean absolute percentage error (MAPE) for the regression model.",
    "function_call": {
      "name": "mean_absolute_percentage_error",
      "arguments": {
        "model": "regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Plot the learning curve of the random forest classifier.",
    "function_call": {
      "name": "model_learning_curve",
      "arguments": {
        "model": "random_forest_classifier",
        "train_sizes": "[0.1, 0.5, 0.8]",
        "cv": "5"
      }
    }
  },
  {
    "instruction": "Create a violin plot for 'income' to visualize distribution.",
    "function_call": {
      "name": "data_visualization_violin_plot",
      "arguments": {
        "feature": "income"
      }
    }
  },
  {
    "instruction": "Analyze collinearity using variance inflation factors (VIF) for all numeric features.",
    "function_call": {
      "name": "collinearity_analysis_vif"
    }
  },
  {
    "instruction": "Train a Gaussian Process Classifier for binary classification.",
    "function_call": {
      "name": "gaussian_process_classifier",
      "arguments": {
        "kernel": "rbf"
      }
    }
  },
  {
    "instruction": "Evaluate model performance using cross-entropy loss.",
    "function_call": {
      "name": "model_evaluation_crossentropy_loss",
      "arguments": {
        "model": "neural_network_classifier"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for the trained K-Nearest Neighbors model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "knn_classifier"
      }
    }
  },
  {
    "instruction": "Use Principal Component Analysis (PCA) to reduce dimensionality to 2.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Detect and remove outliers from 'featureZ' using IQR method.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "removal",
        "column": "featureZ",
        "method": "iqr"
      }
    }
  },
  {
    "instruction": "Train a Gradient Boosting Regressor with 100 estimators.",
    "function_call": {
      "name": "gradient_boosting_regressor",
      "arguments": {
        "n_estimators": "100"
      }
    }
  },
  {
    "instruction": "Visualize the ROC curve for the logistic regression model.",
    "function_call": {
      "name": "model_evaluation_roc_curve",
      "arguments": {
        "model": "logistic_regression",
        "plot": true
      }
    }
  },
  {
    "instruction": "Calculate the explained variance score for the linear regression model.",
    "function_call": {
      "name": "explained_variance_score",
      "arguments": {
        "model": "linear_regression",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Save the current state of the random forest model as 'rf_model.pkl'.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "filename": "rf_model.pkl",
        "model": "random_forest_model"
      }
    }
  },
  {
    "instruction": "Perform a train-test split with a 70/30 ratio.",
    "function_call": {
      "name": "data_split_train_test",
      "arguments": {
        "test_size": "0.3"
      }
    }
  },
  {
    "instruction": "Apply the LDA transformation to the dataset.",
    "function_call": {
      "name": "linear_discriminant_analysis"
    }
  },
  {
    "instruction": "Visualize the distribution of classes in 'target' using a pie chart.",
    "function_call": {
      "name": "data_visualization_pie_chart",
      "arguments": {
        "feature": "target"
      }
    }
  },
  {
    "instruction": "Calculate the silhouette score for the K-means clustering.",
    "function_call": {
      "name": "clustering_evaluation_silhouette_score",
      "arguments": {
        "model": "kmeans",
        "data": "cluster_data"
      }
    }
  },
  {
    "instruction": "Compute the precision per class for the random forest classifier.",
    "function_call": {
      "name": "model_evaluation_precision_per_class",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Generate a word cloud from the 'text' column in the dataset.",
    "function_call": {
      "name": "data_visualization_wordcloud",
      "arguments": {
        "column": "text"
      }
    }
  },
  {
    "instruction": "Train a LightGBM classifier for classification tasks.",
    "function_call": {
      "name": "lightgbm_classifier"
    }
  },
  {
    "instruction": "Calculate the adjusted R-squared for the multiple regression model.",
    "function_call": {
      "name": "adjusted_r_squared",
      "arguments": {
        "model": "multiple_regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Create a box plot for 'featureX' grouped by 'categoryY'.",
    "function_call": {
      "name": "data_visualization_grouped_boxplot",
      "arguments": {
        "feature": "featureX",
        "by": "categoryY"
      }
    }
  },
  {
    "instruction": "Perform hierarchical clustering with Ward's method.",
    "function_call": {
      "name": "hierarchical_clustering",
      "arguments": {
        "linkage": "ward"
      }
    }
  },
  {
    "instruction": "Calculate the Matthews Correlation Coefficient for the binary classifier.",
    "function_call": {
      "name": "model_evaluation_matthews_corrcoef",
      "arguments": {
        "model": "binary_classifier"
      }
    }
  },
  {
    "instruction": "Plot the precision-recall curve for the SVM model.",
    "function_call": {
      "name": "model_evaluation_precision_recall_curve",
      "arguments": {
        "model": "svm",
        "plot": true
      }
    }
  },
  {
    "instruction": "Visualize the decision boundaries of the trained decision tree classifier.",
    "function_call": {
      "name": "decision_tree_decision_boundaries"
    }
  },
  {
    "instruction": "Calculate the feature importances using permutation importance.",
    "function_call": {
      "name": "permutation_importance",
      "arguments": {
        "model": "trained_model",
        "data": "test_set",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix for feature interaction analysis.",
    "function_call": {
      "name": "scatter_matrix_interactions",
      "arguments": {
        "features": "featureA,featureB,featureC"
      }
    }
  },
  {
    "instruction": "Evaluate the null hypothesis using chi-squared test on two categorical variables.",
    "function_call": {
      "name": "statistical_test_chi_squared",
      "arguments": {
        "variable1": "category1",
        "variable2": "category2"
      }
    }
  },
  {
    "instruction": "Apply Isolation Forest for anomaly detection.",
    "function_call": {
      "name": "anomaly_detection_isolation_forest"
    }
  },
  {
    "instruction": "Calculate the coefficient of determination (R²) for the trained model.",
    "function_call": {
      "name": "r_squared",
      "arguments": {
        "model": "trained_regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Visualize the feature importance of the random forest model as a horizontal bar chart.",
    "function_call": {
      "name": "feature_importance_horizontal_bar_chart",
      "arguments": {
        "model": "random_forest_model"
      }
    }
  },
  {
    "instruction": "Train a simple linear regression model on the dataset.",
    "function_call": {
      "name": "simple_linear_regression"
    }
  },
  {
    "instruction": "Perform feature selection using Recursive Feature Elimination (RFE) with the RandomForestClassifier.",
    "function_call": {
      "name": "feature_selection_recursive_elimination",
      "arguments": {
        "model": "random_forest",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Calculate the Jaccard similarity score between two classification models.",
    "function_call": {
      "name": "model_evaluation_jaccard_similarity",
      "arguments": {
        "model1": "model_A",
        "model2": "model_B"
      }
    }
  },
  {
    "instruction": "Train a simple neural network with 2 hidden layers.",
    "function_call": {
      "name": "neural_network_simple_structure",
      "arguments": {
        "hidden_layers": "[16, 8]"
      }
    }
  },
  {
    "instruction": "Evaluate the model's AUC-ROC curve over multiple thresholds.",
    "function_call": {
      "name": "evaluate_auc_roc_thresholds",
      "arguments": {
        "model": "binary_classifier",
        "thresholds": "[0.1, 0.3, 0.5, 0.7, 0.9]"
      }
    }
  },
  {
    "instruction": "Calculate the F-beta score with beta=0.5 for the classification model.",
    "function_call": {
      "name": "model_evaluation_f_beta_score",
      "arguments": {
        "model": "classification_model",
        "beta": "0.5"
      }
    }
  },
  {
    "instruction": "Plot the feature importances as a waterfall chart.",
    "function_call": {
      "name": "feature_importance_waterfall_chart",
      "arguments": {
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Visualize the feature distribution using a density plot for 'featureX'.",
    "function_call": {
      "name": "data_visualization_density_plot",
      "arguments": {
        "feature": "featureX"
      }
    }
  },
  {
    "instruction": "Train a Multinomial Naive Bayes classifier.",
    "function_call": {
      "name": "naive_bayes_classifier",
      "arguments": {
        "algo": "multinomial"
      }
    }
  },
  {
    "instruction": "Evaluate the model's F1 macro score.",
    "function_call": {
      "name": "model_evaluation_f1_score",
      "arguments": {
        "model": "model_instance",
        "average": "macro"
      }
    }
  },
  {
    "instruction": "Plot the learning curves for multiple models on the same plot.",
    "function_call": {
      "name": "model_learning_curves_comparison"
    }
  },
  {
    "instruction": "Create a stacked bar chart showing class distribution in the dataset.",
    "function_call": {
      "name": "data_visualization_stacked_bar_chart"
    }
  },
  {
    "instruction": "Train a CatBoost Classifier for categorical features.",
    "function_call": {
      "name": "catboost_classifier"
    }
  },
  {
    "instruction": "Calculate the mean absolute error (MAE) for the model predictions.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Plot the feature importances of the XGBoost model as a heatmap.",
    "function_call": {
      "name": "feature_importance_heatmap",
      "arguments": {
        "model": "xgb_classifier"
      }
    }
  },
  {
    "instruction": "Implement feature selection using LASSO regularization.",
    "function_call": {
      "name": "feature_selection_lasso_regression"
    }
  },
  {
    "instruction": "Analyze the data for null values and display the count.",
    "function_call": {
      "name": "data_null_value_analysis"
    }
  },
  {
    "instruction": "Plot a line chart for the time series 'sales' over time.",
    "function_call": {
      "name": "time_series_line_chart",
      "arguments": {
        "feature": "sales",
        "time_column": "date"
      }
    }
  },
  {
    "instruction": "Create a dendrogram to visualize hierarchical clustering results.",
    "function_call": {
      "name": "visualize_dendrogram"
    }
  },
  {
    "instruction": "Evaluate the model using the Cohen's Kappa score.",
    "function_call": {
      "name": "model_evaluation_cohens_kappa",
      "arguments": {
        "model": "classification_model"
      }
    }
  },
  {
    "instruction": "Train a LightGBM Regressor for regression tasks.",
    "function_call": {
      "name": "lightgbm_regressor"
    }
  },
  {
    "instruction": "Plot the feature importances of the decision tree in a bar chart.",
    "function_call": {
      "name": "decision_tree_feature_importance_bar"
    }
  },
  {
    "instruction": "Calculate the balanced accuracy score for an imbalanced dataset.",
    "function_call": {
      "name": "model_evaluation_balanced_accuracy",
      "arguments": {
        "model": "classification_model"
      }
    }
  },
  {
    "instruction": "Create a scatter plot with 'feature1' on x-axis and 'feature2' on y-axis.",
    "function_call": {
      "name": "data_visualization_scatter_plot",
      "arguments": {
        "x": "feature1",
        "y": "feature2"
      }
    }
  },
  {
    "instruction": "Train a stacked ensemble model using multiple base learners.",
    "function_call": {
      "name": "stacked_ensemble_model"
    }
  },
  {
    "instruction": "Perform principal component analysis (PCA) with 2 components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2",
        "visualize": true
      }
    }
  },
  {
    "instruction": "Calculate the area under the PR curve (AUPRC) for the model.",
    "function_call": {
      "name": "model_evaluation_auprc",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Visualize the decision boundaries of a classifier on a 2D dataset.",
    "function_call": {
      "name": "classifier_decision_boundaries_2d"
    }
  },
  {
    "instruction": "Train a simple autoencoder for unsupervised feature learning.",
    "function_call": {
      "name": "autoencoder_training"
    }
  },
  {
    "instruction": "Apply t-SNE for dimensionality reduction and visualization.",
    "function_call": {
      "name": "dimensionality_reduction_tsne"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows index for the clustering results.",
    "function_call": {
      "name": "clustering_evaluation_fowlkes_mallows",
      "arguments": {
        "true_labels": "true_labels",
        "predicted_labels": "predicted_labels"
      }
    }
  },
  {
    "instruction": "Create a box plot for each feature to check for outliers.",
    "function_call": {
      "name": "data_visualization_individual_boxplots"
    }
  },
  {
    "instruction": "Train a stacked LSTM model for time series forecasting.",
    "function_call": {
      "name": "lstm_time_series_forecasting"
    }
  },
  {
    "instruction": "Calculate the Matthews correlation coefficient for binary classification.",
    "function_call": {
      "name": "model_evaluation_matthews_cc",
      "arguments": {
        "model": "binary_classifier"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix as a heatmap.",
    "function_call": {
      "name": "confusion_matrix_heatmap",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Train a deep feedforward neural network with 3 hidden layers.",
    "function_call": {
      "name": "deep_neural_network",
      "arguments": {
        "hidden_layers": "[64, 32, 16]"
      }
    }
  },
  {
    "instruction": "Evaluate model performance with precision at top K predictions.",
    "function_call": {
      "name": "model_evaluation_precision_at_k",
      "arguments": {
        "model": "classifier_model",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Perform time series decomposition to analyze trend and seasonality.",
    "function_call": {
      "name": "time_series_decomposition"
    }
  },
  {
    "instruction": "Visualize the distribution of a categorical variable using a count plot.",
    "function_call": {
      "name": "data_visualization_count_plot",
      "arguments": {
        "feature": "category"
      }
    }
  },
  {
    "instruction": "Calculate the silhouette score for KMeans clustering validation.",
    "function_call": {
      "name": "clustering_validation_silhouette"
    }
  },
  {
    "instruction": "Create a word embedding visualization for text data.",
    "function_call": {
      "name": "word_embedding_visualization"
    }
  },
  {
    "instruction": "Train a gradient-boosted decision tree for regression.",
    "function_call": {
      "name": "gradient_boosted_regression_tree"
    }
  },
  {
    "instruction": "Plot a residual plot to check model assumptions.",
    "function_call": {
      "name": "residual_plot_regression"
    }
  },
  {
    "instruction": "Analyze the feature importances using permutation feature importance.",
    "function_call": {
      "name": "permutation_feature_importance"
    }
  },
  {
    "instruction": "Visualize the ROC curves for multiple models in one plot.",
    "function_call": {
      "name": "roc_curves_comparison"
    }
  },
  {
    "instruction": "Calculate the Gini impurity for the decision tree's node split.",
    "function_call": {
      "name": "decision_tree_gini_impurity"
    }
  },
  {
    "instruction": "Train a model with early stopping using validation data.",
    "function_call": {
      "name": "early_stopping_model_training"
    }
  },
  {
    "instruction": "Create a word cloud from customer reviews.",
    "function_call": {
      "name": "wordcloud_from_reviews",
      "arguments": {
        "text_column": "reviews"
      }
    }
  },
  {
    "instruction": "Evaluate the model's calibration with a reliability diagram.",
    "function_call": {
      "name": "model_calibration_reliability_diagram",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared log error for regression predictions.",
    "function_call": {
      "name": "mean_squared_log_error",
      "arguments": {
        "model": "regression_model",
        "data": "test_set"
      }
    }
  },
  {
    "instruction": "Visualize the class separability using PCA and scatter plot.",
    "function_call": {
      "name": "pca_class_separability"
    }
  },
  {
    "instruction": "Train a model with cross-validation to avoid overfitting.",
    "function_call": {
      "name": "model_cross_validation"
    }
  },
  {
    "instruction": "Create a stacked bar chart for feature counts across categories.",
    "function_call": {
      "name": "feature_counts_stacked_bar_chart"
    }
  },
  {
    "instruction": "Calculate the F-max score for imbalanced classification tasks.",
    "function_call": {
      "name": "model_evaluation_f_max_score",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Visualize the change in model performance over epochs.",
    "function_call": {
      "name": "training_performance_over_epochs"
    }
  },
  {
    "instruction": "Perform feature selection using SelectKBest with chi-square test.",
    "function_call": {
      "name": "select_k_best_features"
    }
  },
  {
    "instruction": "Evaluate the model's null accuracy.",
    "function_call": {
      "name": "model_evaluation_null_accuracy",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Perform anomaly detection using Isolation Forest on 'sensor_data'.",
    "function_call": {
      "name": "anomaly_detection_isolation_forest",
      "arguments": {
        "data": "sensor_data"
      }
    }
  },
  {
    "instruction": "Calculate the Hoeffding’s D statistic to measure independence between two features.",
    "function_call": {
      "name": "measure_feature_independence_hoeffdings_d",
      "arguments": {
        "feature1": "featureA",
        "feature2": "featureB"
      }
    }
  },
  {
    "instruction": "Create a word frequency table from 'text_data'.",
    "function_call": {
      "name": "text_analysis_word_frequency",
      "arguments": {
        "text_column": "text_data"
      }
    }
  },
  {
    "instruction": "Train a simple autoencoder for noise reduction on 'image_data'.",
    "function_call": {
      "name": "autoencoder_noise_reduction",
      "arguments": {
        "data": "image_data"
      }
    }
  },
  {
    "instruction": "Plot the learning curve of a neural network with varying complexities.",
    "function_call": {
      "name": "neural_network_learning_curve_complexity"
    }
  },
  {
    "instruction": "Apply DBSCAN clustering with dynamic epsilon based on distance to 'density_data'.",
    "function_call": {
      "name": "dynamic_dbscan_clustering"
    }
  },
  {
    "instruction": "Evaluate the model's null hypothesis using permutation testing.",
    "function_call": {
      "name": "permutation_testing_null_hypothesis"
    }
  },
  {
    "instruction": "Create a Sankey diagram to visualize flow between categories.",
    "function_call": {
      "name": "visualize_sankey_flow",
      "arguments": {
        "categories": "category_data"
      }
    }
  },
  {
    "instruction": "Calculate the mutual information between 'featureX' and 'target' for feature selection.",
    "function_call": {
      "name": "feature_selection_mutual_information",
      "arguments": {
        "feature": "featureX",
        "target": "target"
      }
    }
  },
  {
    "instruction": "Train a model using the ExtraTreesClassifier for feature importance estimation.",
    "function_call": {
      "name": "feature_importance_extra_trees_classifier"
    }
  },
  {
    "instruction": "Plot the ROC curve for different thresholds for binary classification.",
    "function_call": {
      "name": "roc_curve_thresholds"
    }
  },
  {
    "instruction": "Evaluate model performance with Brier score.",
    "function_call": {
      "name": "model_evaluation_brier_score",
      "arguments": {
        "model": "classification_model"
      }
    }
  },
  {
    "instruction": "Visualize the decision tree structure.",
    "function_call": {
      "name": "visualize_decision_tree_structure"
    }
  },
  {
    "instruction": "Calculate the Jaccard similarity between two datasets.",
    "function_call": {
      "name": "dataset_similarity_jaccard"
    }
  },
  {
    "instruction": "Train a stacked ensemble using cross-validation scores.",
    "function_call": {
      "name": "stacked_ensemble_cross_val_scores"
    }
  },
  {
    "instruction": "Create a heatmap of feature correlations with respect to 'target_variable'.",
    "function_call": {
      "name": "correlation_heatmap_target",
      "arguments": {
        "target": "target_variable"
      }
    }
  },
  {
    "instruction": "Perform time series forecasting with Facebook Prophet.",
    "function_call": {
      "name": "time_series_forecasting_prophet"
    }
  },
  {
    "instruction": "Visualize the t-SNE projection of high-dimensional data.",
    "function_call": {
      "name": "visualize_tsne_projection"
    }
  },
  {
    "instruction": "Calculate the Gini index for a decision tree split.",
    "function_call": {
      "name": "decision_tree_gini_index"
    }
  },
  {
    "instruction": "Train a model with early stopping based on validation loss.",
    "function_call": {
      "name": "early_stopping_by_loss"
    }
  },
  {
    "instruction": "Calculate the precision at a specific threshold.",
    "function_call": {
      "name": "precision_at_threshold",
      "arguments": {
        "model": "classifier_model",
        "threshold": "0.8"
      }
    }
  },
  {
    "instruction": "Create a histogram of residuals for regression diagnostics.",
    "function_call": {
      "name": "regression_residual_histogram"
    }
  },
  {
    "instruction": "Perform time series decomposition using STL.",
    "function_call": {
      "name": "time_series_decomposition_stl"
    }
  },
  {
    "instruction": "Visualize feature interactions using a partial dependence plot.",
    "function_call": {
      "name": "partial_dependence_plot",
      "arguments": {
        "features": "featureA,featureB",
        "model": "model_instance"
      }
    }
  },
  {
    "instruction": "Evaluate the model's calibration with Platt scaling.",
    "function_call": {
      "name": "model_calibration_platt_scaling",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Calculate the adjusted rand index for cluster evaluation.",
    "function_call": {
      "name": "cluster_evaluation_adjusted_rand_index"
    }
  },
  {
    "instruction": "Visualize the confusion matrix as a heatmap with normalized values.",
    "function_call": {
      "name": "confusion_matrix_normalized_heatmap"
    }
  },
  {
    "instruction": "Train a stacked generalization model with meta-learner.",
    "function_call": {
      "name": "stacked_generalization"
    }
  },
  {
    "instruction": "Perform feature selection using Recursive Feature Elimination with Cross-Validation.",
    "function_call": {
      "name": "rfe_with_cross_validation"
    }
  },
  {
    "instruction": "Calculate the Matthews correlation coefficient for multiclass classification.",
    "function_call": {
      "name": "matthews_corrcoef_multiclass",
      "arguments": {
        "model": "classifier_model"
      }
    }
  },
  {
    "instruction": "Create a box plot to compare distributions across categories.",
    "function_call": {
      "name": "compare_categories_boxplot",
      "arguments": {
        "categories": "category_list",
        "feature": "feature_to_compare"
      }
    }
  },
  {
    "instruction": "Evaluate model stability using bootstrapped samples.",
    "function_call": {
      "name": "model_stability_bootstrapped"
    }
  },
  {
    "instruction": "Train a deep learning model with dropout regularization.",
    "function_call": {
      "name": "deep_learning_dropout_regularization"
    }
  },
  {
    "instruction": "Calculate the mean absolute percentage error for regression analysis.",
    "function_call": {
      "name": "mean_absolute_percentage_error_regression"
    }
  },
  {
    "instruction": "Plot feature importances for a random forest model using bar charts.",
    "function_call": {
      "name": "random_forest_feature_importance_barchart"
    }
  },
  {
    "instruction": "Create a PCA-based scatter plot for visualizing multi-dimensional data.",
    "function_call": {
      "name": "pca_scatter_plot"
    }
  },
  {
    "instruction": "Train a model with early stopping based on validation accuracy.",
    "function_call": {
      "name": "early_stopping_by_accuracy"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows index for cluster purity.",
    "function_call": {
      "name": "cluster_purity_fowlkes_mallows"
    }
  },
  {
    "instruction": "Visualize the feature importance of a model using a radar chart.",
    "function_call": {
      "name": "feature_importance_radar_chart"
    }
  },
  {
    "instruction": "Evaluate model performance using Cohen's kappa on a classification task.",
    "function_call": {
      "name": "cohen_kappa_score_classification"
    }
  },
  {
    "instruction": "Train a deep learning autoencoder for anomaly detection.",
    "function_call": {
      "name": "autoencoder_anomaly_detection"
    }
  },
  {
    "instruction": "Calculate the area under the ROC curve for multiple thresholds.",
    "function_call": {
      "name": "calculate_auc_multiple_thresholds"
    }
  },
  {
    "instruction": "Visualize the class separability using t-SNE.",
    "function_call": {
      "name": "class_separability_tsne"
    }
  },
  {
    "instruction": "Perform principal component analysis (PCA) with explained variance ratio.",
    "function_call": {
      "name": "pca_explained_variance"
    }
  },
  {
    "instruction": "Evaluate model's precision-recall AUC.",
    "function_call": {
      "name": "precision_recall_auc"
    }
  },
  {
    "instruction": "Train a model using early stopping with custom metric.",
    "function_call": {
      "name": "early_stopping_custom_metric"
    }
  },
  {
    "instruction": "Visualize feature interactions using a scatter matrix.",
    "function_call": {
      "name": "scatter_matrix_interactions"
    }
  },
  {
    "instruction": "Create a feature importance bar chart for random forest.",
    "function_call": {
      "name": "rf_feature_importance_bar"
    }
  },
  {
    "instruction": "Calculate the mutual information gain for feature selection.",
    "function_call": {
      "name": "mutual_information_gain"
    }
  },
  {
    "instruction": "Visualize the feature space using PCA biplot.",
    "function_call": {
      "name": "pca_biplot"
    }
  },
  {
    "instruction": "Train a neural network with batch normalization.",
    "function_call": {
      "name": "neural_network_batch_normalization"
    }
  },
  {
    "instruction": "Evaluate model performance using cross-validated F1 score.",
    "function_call": {
      "name": "cross_validated_f1_score"
    }
  },
  {
    "instruction": "Create a word cloud for text data sentiment analysis.",
    "function_call": {
      "name": "sentiment_analysis_wordcloud"
    }
  },
  {
    "instruction": "Perform hierarchical clustering with different linkage methods.",
    "function_call": {
      "name": "hierarchical_clustering_methods"
    }
  },
  {
    "instruction": "Calculate the silhouette score for different numbers of clusters.",
    "function_call": {
      "name": "silhouette_scores_kmeans"
    }
  },
  {
    "instruction": "Train a model with L1 regularization for feature selection.",
    "function_call": {
      "name": "l1_regularization_feature_selection"
    }
  },
  {
    "instruction": "Visualize decision boundaries of a binary classifier.",
    "function_call": {
      "name": "classifier_decision_boundaries"
    }
  },
  {
    "instruction": "Calculate the H指数 (H-index) for citation analysis.",
    "function_call": {
      "name": "calculate_h_index"
    }
  },
  {
    "instruction": "Perform stratified sampling for class balance.",
    "function_call": {
      "name": "stratified_sampling"
    }
  },
  {
    "instruction": "Visualize the evolution of model loss during training.",
    "function_call": {
      "name": "training_loss_evolution"
    }
  },
  {
    "instruction": "Train a model with dropout to prevent overfitting.",
    "function_call": {
      "name": "dropout_prevent_overfitting"
    }
  },
  {
    "instruction": "Calculate the entropy of the target variable for classification.",
    "function_call": {
      "name": "calculate_entropy_classification"
    }
  },
  {
    "instruction": "Visualize feature importances as a waterfall chart.",
    "function_call": {
      "name": "feature_importance_waterfall"
    }
  },
  {
    "instruction": "Perform time series forecasting with Facebook Prophet for multiple time series.",
    "function_call": {
      "name": "prophet_forecast_multiple_series"
    }
  },
  {
    "instruction": "Evaluate model's calibration curve.",
    "function_call": {
      "name": "model_calibration_curve"
    }
  },
  {
    "instruction": "Create a dendrogram to visualize hierarchical clusters.",
    "function_call": {
      "name": "visualize_hierarchical_clusters"
    }
  },
  {
    "instruction": "Train a stacked ensemble with different base learners and a meta learner.",
    "function_call": {
      "name": "stacked_ensemble_model_meta"
    }
  },
  {
    "instruction": "Calculate the Kullback-Leibler divergence between two distributions.",
    "function_call": {
      "name": "kullback_leibler_divergence"
    }
  },
  {
    "instruction": "Visualize the confusion matrix as a sunburst chart.",
    "function_call": {
      "name": "confusion_matrix_sunburst"
    }
  },
  {
    "instruction": "Evaluate the model's sensitivity and specificity.",
    "function_call": {
      "name": "sensitivity_specificity"
    }
  },
  {
    "instruction": "Perform dimensionality reduction using UMAP.",
    "function_call": {
      "name": "umap_dimensionality_reduction"
    }
  },
  {
    "instruction": "Calculate the Jenson-Shannon divergence between probability distributions.",
    "function_call": {
      "name": "jensen_shannon_divergence"
    }
  },
  {
    "instruction": "Visualize feature co-occurrences in text data.",
    "function_call": {
      "name": "feature_cooccurrence_matrix"
    }
  },
  {
    "instruction": "Train a model with weight decay (L2 regularization).",
    "function_call": {
      "name": "model_weight_decay"
    }
  },
  {
    "instruction": "Create a scatter plot matrix to explore feature relationships.",
    "function_call": {
      "name": "scatter_plot_matrix"
    }
  },
  {
    "instruction": "Calculate the Matthews correlation coefficient for each fold in cross-validation.",
    "function_call": {
      "name": "cross_val_matthews_corrcoef"
    }
  },
  {
    "instruction": "Visualize the feature importances as a heat map.",
    "function_call": {
      "name": "feature_importance_heatmap"
    }
  },
  {
    "instruction": "Train a model with early stopping based on AUC score.",
    "function_call": {
      "name": "early_stopping_auc"
    }
  },
  {
    "instruction": "Calculate the F-score for a multi-class classification task.",
    "function_call": {
      "name": "multi_class_f_score"
    }
  },
  {
    "instruction": "Perform feature ranking using permutation feature importance.",
    "function_call": {
      "name": "permutation_feature_ranking"
    }
  },
  {
    "instruction": "Visualize the t-SNE embedding colored by class labels.",
    "function_call": {
      "name": "tsne_embedding_colored_classes"
    }
  },
  {
    "instruction": "Train a model using transfer learning from a pre-trained model.",
    "function_call": {
      "name": "transfer_learning_model"
    }
  },
  {
    "instruction": "Calculate the Gini index for model evaluation.",
    "function_call": {
      "name": "gini_index_evaluation"
    }
  },
  {
    "instruction": "Create a time series forecast using Facebook Prophet with seasonality adjustments.",
    "function_call": {
      "name": "prophet_forecast_seasonality"
    }
  },
  {
    "instruction": "Visualize the model's feature attributions using SHAP values.",
    "function_call": {
      "name": "shap_values_visualization"
    }
  },
  {
    "instruction": "Perform time series forecasting with SARIMA.",
    "function_call": {
      "name": "sarima_forecasting"
    }
  },
  {
    "instruction": "Evaluate model's performance with Brier Skill Score.",
    "function_call": {
      "name": "brier_skill_score"
    }
  },
  {
    "instruction": "Create a word cloud from customer feedback.",
    "function_call": {
      "name": "customer_feedback_wordcloud"
    }
  },
  {
    "instruction": "Train a model with batch training for large datasets.",
    "function_call": {
      "name": "batch_training_large_datasets"
    }
  },
  {
    "instruction": "Visualize the evolution of feature importances during training.",
    "function_call": {
      "name": "feature_importance_evolution"
    }
  },
  {
    "instruction": "Calculate the precision at top K for a ranking task.",
    "function_call": {
      "name": "precision_at_k_ranking"
    }
  },
  {
    "instruction": "Train a model with early stopping based on a custom callback.",
    "function_call": {
      "name": "early_stopping_custom_callback"
    }
  },
  {
    "instruction": "Visualize model's decision regions in a 2D space.",
    "function_call": {
      "name": "decision_regions_2d"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows index for binary classification.",
    "function_call": {
      "name": "fowlkes_mallows_index_binary"
    }
  },
  {
    "instruction": "Perform feature selection using Boruta algorithm.",
    "function_call": {
      "name": "boruta_feature_selection"
    }
  },
  {
    "instruction": "Create a PCA-based elbow plot for optimal component selection.",
    "function_call": {
      "name": "pca_elbow_method"
    }
  },
  {
    "instruction": "Evaluate model performance with a ROC lift chart.",
    "function_call": {
      "name": "roc_lift_chart"
    }
  },
  {
    "instruction": "Train a model using adaptive learning rates.",
    "function_call": {
      "name": "adaptive_learning_rates_model"
    }
  },
  {
    "instruction": "Visualize the learning curves for different hyperparameters.",
    "function_call": {
      "name": "learning_curves_hyperparameters"
    }
  },
  {
    "instruction": "Calculate the area under the PR curve for multiclass classification.",
    "function_call": {
      "name": "multiclass_auc_pr_curve"
    }
  },
  {
    "instruction": "Perform hierarchical clustering with AgglomerativeClustering.",
    "function_call": {
      "name": "hierarchical_clustering_agglomerative"
    }
  },
  {
    "instruction": "Visualize the dendrogram for hierarchical clustering.",
    "function_call": {
      "name": "visualize_dendrogram"
    }
  },
  {
    "instruction": "Train a model using gradient boosting with early stopping.",
    "function_call": {
      "name": "gradient_boosting_early_stopping"
    }
  },
  {
    "instruction": "Calculate the confusion matrix for multiclass classification.",
    "function_call": {
      "name": "multiclass_confusion_matrix"
    }
  },
  {
    "instruction": "Visualize feature correlations with a heatmap for binary classification.",
    "function_call": {
      "name": "binary_classification_feature_correlation_heatmap"
    }
  },
  {
    "instruction": "Create a 3D scatter plot for three selected features.",
    "function_call": {
      "name": "three_dim_scatter_plot"
    }
  },
  {
    "instruction": "Train a stacked ensemble model with stacking layer.",
    "function_call": {
      "name": "stacked_ensemble_with_stacking_layer"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows index for cluster validation.",
    "function_call": {
      "name": "cluster_analysis_fowlkes_mallows"
    }
  },
  {
    "instruction": "Visualize the ROC curves for multiple models comparison.",
    "function_call": {
      "name": "roc_curves_comparison_plot"
    }
  },
  {
    "instruction": "Perform principal component regression (PCR) for feature reduction.",
    "function_call": {
      "name": "principal_component_regression"
    }
  },
  {
    "instruction": "Train a neural network with dropout and batch normalization layers.",
    "function_call": {
      "name": "neural_network_dropout_batchnorm"
    }
  },
  {
    "instruction": "Evaluate model's robustness using bootstrapped samples.",
    "function_call": {
      "name": "model_robustness_bootstrapping"
    }
  },
  {
    "instruction": "Create a word cloud for sentiment analysis of customer reviews.",
    "function_call": {
      "name": "sentiment_analysis_wordcloud_reviews"
    }
  },
  {
    "instruction": "Calculate the adjusted Rand index for comparing clustering results.",
    "function_call": {
      "name": "adjusted_rand_index_clustering"
    }
  },
  {
    "instruction": "Visualize the evolution of model weights during training.",
    "function_call": {
      "name": "visualize_model_weights_evolution"
    }
  },
  {
    "instruction": "Train a model using a learning rate scheduler.",
    "function_call": {
      "name": "model_with_learning_rate_scheduler"
    }
  },
  {
    "instruction": "Evaluate model's feature importances using permutation tests.",
    "function_call": {
      "name": "permutation_importance_evaluation"
    }
  },
  {
    "instruction": "Visualize feature importances using a parallel coordinates plot.",
    "function_call": {
      "name": "parallel_coordinates_feature_importance"
    }
  },
  {
    "instruction": "Calculate the precision, recall, and F1-score for each class in multiclass classification.",
    "function_call": {
      "name": "multiclass_metrics"
    }
  },
  {
    "instruction": "Perform feature extraction with Bag-of-Words for text classification.",
    "function_call": {
      "name": "text_classification_bag_of_words"
    }
  },
  {
    "instruction": "Train a model with online learning capabilities.",
    "function_call": {
      "name": "online_learning_model"
    }
  },
  {
    "instruction": "Visualize the model's decision boundaries in a 2-class problem.",
    "function_call": {
      "name": "decision_boundaries_2class"
    }
  },
  {
    "instruction": "Calculate the Gini coefficient for income inequality analysis.",
    "function_call": {
      "name": "gini_coefficient_income"
    }
  },
  {
    "instruction": "Create a word embedding visualization using T-SNE.",
    "function_call": {
      "name": "word_embedding_t_sne"
    }
  },
  {
    "instruction": "Perform dimensionality reduction with Non-negative Matrix Factorization (NMF).",
    "function_call": {
      "name": "nmf_dimensionality_reduction"
    }
  },
  {
    "instruction": "Visualize feature correlations with a network graph.",
    "function_call": {
      "name": "feature_correlation_network_graph"
    }
  },
  {
    "instruction": "Train a model with L2 regularization for better generalization.",
    "function_call": {
      "name": "model_l2_regularization"
    }
  },
  {
    "instruction": "Evaluate the model's performance with cross-validation using stratification.",
    "function_call": {
      "name": "stratified_cross_validation_performance"
    }
  },
  {
    "instruction": "Visualize the evolution of model's loss and accuracy during epochs.",
    "function_call": {
      "name": "model_loss_accuracy_evolution"
    }
  },
  {
    "instruction": "Create a time series decomposition plot with trend, seasonality, and residuals.",
    "function_call": {
      "name": "time_series_decomposition_plot"
    }
  },
  {
    "instruction": "Train a model using adaptive learning rate methods like AdamW.",
    "function_call": {
      "name": "adaptive_learning_rate_model_adamw"
    }
  },
  {
    "instruction": "Calculate the entropy of a feature for feature selection.",
    "function_call": {
      "name": "feature_entropy"
    }
  },
  {
    "instruction": "Visualize the distribution of classes in a dataset.",
    "function_call": {
      "name": "class_distribution_histogram"
    }
  },
  {
    "instruction": "Perform feature extraction with FastICA for feature decorrelation.",
    "function_call": {
      "name": "feature_extraction_fast_ica"
    }
  },
  {
    "instruction": "Train a model with early stopping on validation loss and accuracy.",
    "function_call": {
      "name": "early_stopping_loss_accuracy"
    }
  },
  {
    "instruction": "Visualize the relationship between two continuous variables using a hexbin plot.",
    "function_call": {
      "name": "hexbin_plot_relationship"
    }
  },
  {
    "instruction": "Evaluate the model's calibration with reliability diagrams.",
    "function_call": {
      "name": "model_calibration_reliability_diagrams"
    }
  },
  {
    "instruction": "Create a stacked bar chart for categorical feature distributions.",
    "function_call": {
      "name": "categorical_feature_stacked_bar"
    }
  },
  {
    "instruction": "Perform feature selection using Genetic Algorithms.",
    "function_call": {
      "name": "feature_selection_genetic_algorithms"
    }
  },
  {
    "instruction": "Visualize the model's feature importances as a treemap.",
    "function_call": {
      "name": "feature_importance_treemap"
    }
  },
  {
    "instruction": "Train a model with dropout to prevent overfitting in convolutional neural networks.",
    "function_call": {
      "name": "cnn_with_dropout"
    }
  },
  {
    "instruction": "Calculate the Matthew's correlation coefficient for binary classification tasks.",
    "function_call": {
      "name": "matthews_correlation_coefficient_binary"
    }
  },
  {
    "instruction": "Perform data augmentation for image classification using rotation.",
    "function_call": {
      "name": "image_classification_data_augmentation_rotation"
    }
  },
  {
    "instruction": "Visualize the model's learning rate schedule over epochs.",
    "function_call": {
      "name": "learning_rate_schedule_visualization"
    }
  },
  {
    "instruction": "Calculate the explained variance for each principal component.",
    "function_call": {
      "name": "explained_variance_principal_components"
    }
  },
  {
    "instruction": "Train a model using online stochastic gradient descent.",
    "function_call": {
      "name": "online_sgd_model_training"
    }
  },
  {
    "instruction": "Visualize the top contributing features to a random forest model.",
    "function_call": {
      "name": "top_random_forest_contributing_features"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows score for clustering evaluation.",
    "function_call": {
      "name": "fowlkes_mallows_score"
    }
  },
  {
    "instruction": "Train a model with early stopping on a validation set.",
    "function_call": {
      "name": "early_stopping_model_validation"
    }
  },
  {
    "instruction": "Visualize the model's decision tree for interpretability.",
    "function_call": {
      "name": "decision_tree_interpretation_visualization"
    }
  },
  {
    "instruction": "Perform time series forecasting with Facebook Prophet for multiple seasons.",
    "function_call": {
      "name": "prophet_forecasting_multi_seasonality"
    }
  },
  {
    "instruction": "Calculate the Jensen-Shannon distance between two probability distributions.",
    "function_call": {
      "name": "jensen_shannon_distance"
    }
  },
  {
    "instruction": "Visualize feature importance using a sunburst chart.",
    "function_call": {
      "name": "feature_importance_sunburst"
    }
  },
  {
    "instruction": "Create a word frequency analysis for a text corpus.",
    "function_call": {
      "name": "text_corpus_word_frequency"
    }
  },
  {
    "instruction": "Train a model with transfer learning from a pre-trained CNN.",
    "function_call": {
      "name": "transfer_learning_cnn"
    }
  },
  {
    "instruction": "Visualize feature interactions in a pair plot for correlation analysis.",
    "function_call": {
      "name": "pair_plot_interactions"
    }
  },
  {
    "instruction": "Calculate the precision-recall curve for a binary classification model.",
    "function_call": {
      "name": "precision_recall_curve_binary"
    }
  },
  {
    "instruction": "Train a model using early stopping based on validation loss and metric improvement.",
    "function_call": {
      "name": "early_stopping_metric_improvement"
    }
  },
  {
    "instruction": "Visualize the model's decision boundaries in 3D.",
    "function_call": {
      "name": "decision_boundaries_3d"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows index for cluster evaluation with custom clusters.",
    "function_call": {
      "name": "custom_clusters_fowlkes_mallows"
    }
  },
  {
    "instruction": "Perform feature selection using Recursive Feature Elimination with Cross-Validation (RFECV).",
    "function_call": {
      "name": "rfecv_feature_selection"
    }
  },
  {
    "instruction": "Visualize the class distribution with a pie chart.",
    "function_call": {
      "name": "class_distribution_pie_chart"
    }
  },
  {
    "instruction": "Train a model with early stopping based on a custom scoring function.",
    "function_call": {
      "name": "early_stopping_custom_scoring"
    }
  },
  {
    "instruction": "Calculate the Jaccard similarity score between two datasets.",
    "function_call": {
      "name": "jaccard_similarity_score"
    }
  },
  {
    "instruction": "Visualize the model's feature importances as a beeswarm plot.",
    "function_call": {
      "name": "feature_importance_beeswarm"
    }
  },
  {
    "instruction": "Create a scatter plot matrix for feature interaction analysis.",
    "function_call": {
      "name": "scatter_matrix_interactions"
    }
  },
  {
    "instruction": "Train a model with online learning for real-time updates.",
    "function_call": {
      "name": "online_learning_realtime_updates"
    }
  },
  {
    "instruction": "Calculate the precision at different recall levels for model evaluation.",
    "function_call": {
      "name": "precision_recall_curve"
    }
  },
  {
    "instruction": "Visualize the model's architecture for explainability.",
    "function_call": {
      "name": "model_architecture_visualization"
    }
  },
  {
    "instruction": "Perform dimensionality reduction with UMAP for visualization.",
    "function_call": {
      "name": "umap_dimensionality_reduction_visual"
    }
  },
  {
    "instruction": "Train a model with adaptive learning rates using the Adagrad optimizer.",
    "function_call": {
      "name": "model_adaptive_learning_rates_adagrad"
    }
  },
  {
    "instruction": "Visualize the feature importances using a force-directed graph.",
    "function_call": {
      "name": "feature_importance_force_directed"
    }
  },
  {
    "instruction": "Calculate the Brier score for probabilistic predictions.",
    "function_call": {
      "name": "brier_score_probabilistic_predictions"
    }
  },
  {
    "instruction": "Train a model using a learning schedule with cosine annealing.",
    "function_call": {
      "name": "cosine_annealing_learning_schedule"
    }
  },
  {
    "instruction": "Visualize the evolution of feature importances over epochs.",
    "function_call": {
      "name": "feature_importance_epochs_evolution"
    }
  },
  {
    "instruction": "Calculate the Gini index for a classification model.",
    "function_call": {
      "name": "classification_model_gini_index"
    }
  },
  {
    "instruction": "Perform clustering analysis with DBSCAN using elbow method for optimal eps.",
    "function_call": {
      "name": "dbscan_optimal_eps_elbow"
    }
  },
  {
    "instruction": "Visualize the model's attention weights for sequence data.",
    "function_call": {
      "name": "attention_weights_sequence_data"
    }
  },
  {
    "instruction": "Calculate the F-beta score for imbalanced datasets.",
    "function_call": {
      "name": "f_beta_score_imbalanced"
    }
  },
  {
    "instruction": "Train a model with a custom loss function.",
    "function_call": {
      "name": "model_custom_loss_function"
    }
  },
  {
    "instruction": "Visualize the model's confusion matrix with normalized values.",
    "function_call": {
      "name": "normalized_confusion_matrix"
    }
  },
  {
    "instruction": "Calculate the Matthews correlation coefficient for a multiclass problem.",
    "function_call": {
      "name": "matthews_correlation_coefficient_multiclass"
    }
  },
  {
    "instruction": "Perform feature extraction with PCA for dimensionality reduction.",
    "function_call": {
      "name": "pca_feature_extraction"
    }
  },
  {
    "instruction": "Visualize the model's ROC curve for multiple thresholds.",
    "function_call": {
      "name": "roc_curve_threshold_variation"
    }
  },
  {
    "instruction": "Calculate the silhouette score for different clustering algorithms.",
    "function_call": {
      "name": "silhouette_scores_algorithms"
    }
  },
  {
    "instruction": "Train a model using transfer learning from a pre-trained language model.",
    "function_call": {
      "name": "transfer_learning_language_model"
    }
  },
  {
    "instruction": "Visualize the feature importances using a heat map with categories.",
    "function_call": {
      "name": "categorical_feature_importance_heatmap"
    }
  },
  {
    "instruction": "Calculate the F-test score for feature selection.",
    "function_call": {
      "name": "f_test_score_feature_selection"
    }
  },
  {
    "instruction": "Train a model using early stopping with patience.",
    "function_call": {
      "name": "early_stopping_patience"
    }
  },
  {
    "instruction": "Visualize the model's training and validation loss curves.",
    "function_call": {
      "name": "loss_curves_training_validation"
    }
  },
  {
    "instruction": "Calculate the area under the PR curve for each class in multiclass classification.",
    "function_call": {
      "name": "multiclass_auc_pr_curve"
    }
  },
  {
    "instruction": "Perform feature selection using mutual information for regression tasks.",
    "function_call": {
      "name": "mutual_information_regression_feature_selection"
    }
  },
  {
    "instruction": "Visualize the model's decision rules for interpretability.",
    "function_call": {
      "name": "decision_rules_interpretability"
    }
  },
  {
    "instruction": "Calculate the Kolmogorov-Smirnov test for normality.",
    "function_call": {
      "name": "kolmogorov_smirnov_test_normality"
    }
  },
  {
    "instruction": "Train a model with L1 regularization for feature sparsity.",
    "function_call": {
      "name": "model_l1_regularization"
    }
  },
  {
    "instruction": "Visualize the feature importance using a radar chart for multiple models.",
    "function_call": {
      "name": "multi_model_feature_importance_radar"
    }
  },
  {
    "instruction": "Calculate the area under the ROC curve for binary classification.",
    "function_call": {
      "name": "binary_classification_auc_roc"
    }
  },
  {
    "instruction": "Perform data balancing using SMOTE technique.",
    "function_call": {
      "name": "data_balancing_smote"
    }
  },
  {
    "instruction": "Visualize the t-SNE projection with color by class.",
    "function_call": {
      "name": "tsne_projection_colored_by_class"
    }
  },
  {
    "instruction": "Calculate the accuracy of the model on a test set.",
    "function_call": {
      "name": "model_test_accuracy"
    }
  },
  {
    "instruction": "Perform hierarchical clustering analysis with Ward's method.",
    "function_call": {
      "name": "hierarchical_clustering_ward"
    }
  },
  {
    "instruction": "Visualize the dendrogram to determine optimal clusters visually.",
    "function_call": {
      "name": "dendrogram_optimal_clusters"
    }
  },
  {
    "instruction": "Train a deep learning model with dropout and batch normalization for improved generalization.",
    "function_call": {
      "name": "deep_learning_dropout_batchnorm_generalization"
    }
  },
  {
    "instruction": "Calculate the precision score for each class in multiclass classification.",
    "function_call": {
      "name": "precision_per_class"
    }
  },
  {
    "instruction": "Create a word cloud to visualize the most frequent words in a text dataset.",
    "function_call": {
      "name": "wordcloud_text_dataset"
    }
  },
  {
    "instruction": "Visualize the feature importances as a radar chart for a random forest model.",
    "function_call": {
      "name": "radar_chart_feature_importance_rf"
    }
  },
  {
    "instruction": "Perform dimensionality reduction using PCA for visualization of high-dimensional data.",
    "function_call": {
      "name": "pca_data_visualization"
    }
  },
  {
    "instruction": "Calculate the mean absolute percentage error for regression predictions.",
    "function_call": {
      "name": "mape_regression"
    }
  },
  {
    "instruction": "Train a model with early stopping using a custom metric.",
    "function_call": {
      "name": "early_stopping_custom_metric"
    }
  },
  {
    "instruction": "Visualize the class distribution using a stacked bar chart.",
    "function_call": {
      "name": "class_distribution_stacked_bar"
    }
  },
  {
    "instruction": "Calculate the F-statistic for feature selection in regression models.",
    "function_call": {
      "name": "f_statistic_regression_features"
    }
  },
  {
    "instruction": "Perform principal component regression for dimensionality reduction in regression tasks.",
    "function_call": {
      "name": "principal_component_regression_analysis"
    }
  },
  {
    "instruction": "Visualize the model's confusion matrix with class labels.",
    "function_call": {
      "name": "confusion_matrix_class_labels"
    }
  },
  {
    "instruction": "Calculate the calibration curve for a probabilistic classifier.",
    "function_call": {
      "name": "calibration_curve_classifier"
    }
  },
  {
    "instruction": "Train a model with gradient boosting and early stopping.",
    "function_call": {
      "name": "gradient_boosting_early_stopping"
    }
  },
  {
    "instruction": "Visualize feature correlations using a correlation matrix heatmap.",
    "function_call": {
      "name": "correlation_matrix_heatmap"
    }
  },
  {
    "instruction": "Calculate the adjusted Rand index for comparing two clusterings.",
    "function_call": {
      "name": "adjusted_rand_index_comparing_clusterings"
    }
  },
  {
    "instruction": "Train a model using transfer learning from a pre-trained model and fine-tuning.",
    "function_call": {
      "name": "transfer_learning_finetuning"
    }
  },
  {
    "instruction": "Visualize the learning curve of a model to analyze bias-variance trade-off.",
    "function_call": {
      "name": "learning_curve_analysis"
    }
  },
  {
    "instruction": "Calculate the mutual information gain for categorical features.",
    "function_call": {
      "name": "mutual_information_categorical_features"
    }
  },
  {
    "instruction": "Perform data augmentation for image datasets to increase diversity.",
    "function_call": {
      "name": "image_data_augmentation"
    }
  },
  {
    "instruction": "Visualize the model's performance using an ROC curve for multiple thresholds.",
    "function_call": {
      "name": "roc_curve_multiple_thresholds"
    }
  },
  {
    "instruction": "Calculate the Gini index for a classification task.",
    "function_call": {
      "name": "classification_task_gini_index"
    }
  },
  {
    "instruction": "Train a model using online learning with mini-batches.",
    "function_call": {
      "name": "online_learning_mini_batches"
    }
  },
  {
    "instruction": "Visualize the model's decision boundaries with different colors for classes.",
    "function_call": {
      "name": "decision_boundaries_multiclass"
    }
  },
  {
    "instruction": "Calculate the Brier score for probabilistic predictions in a binary classification task.",
    "function_call": {
      "name": "brier_score_binary_classification"
    }
  },
  {
    "instruction": "Train a model using a learning schedule that decays over time.",
    "function_call": {
      "name": "learning_schedule_decay"
    }
  },
  {
    "instruction": "Visualize the feature importances using a circular layout.",
    "function_call": {
      "name": "circular_layout_feature_importance"
    }
  },
  {
    "instruction": "Calculate the Cohen's kappa for inter-rater agreement.",
    "function_call": {
      "name": "cohens_kappa_inter_rater"
    }
  },
  {
    "instruction": "Perform feature selection using recursive feature elimination with cross-validation.",
    "function_call": {
      "name": "rfecv_feature_elimination"
    }
  },
  {
    "instruction": "Visualize the model's coefficients as a bar chart for interpretability.",
    "function_call": {
      "name": "model_coefficients_bar_chart"
    }
  },
  {
    "instruction": "Calculate the precision-recall AUC for a classifier.",
    "function_call": {
      "name": "precision_recall_auc_classifier"
    }
  },
  {
    "instruction": "Train a model using a custom loss function tailored to the problem.",
    "function_call": {
      "name": "custom_loss_function_model"
    }
  },
  {
    "instruction": "Visualize the feature importances using a force-directed graph layout.",
    "function_call": {
      "name": "feature_importance_force_directed_graph"
    }
  },
  {
    "instruction": "Calculate the Fowlkes-Mallows score for comparing cluster assignments.",
    "function_call": {
      "name": "fowlkes_mallows_score_clustering"
    }
  },
  {
    "instruction": "Train a model using Bayesian optimization for hyperparameter tuning.",
    "function_call": {
      "name": "bayesian_optimization_hyperparameter_tuning"
    }
  },
  {
    "instruction": "Visualize the distribution of continuous features using violin plots.",
    "function_call": {
      "name": "continuous_features_violin_plots"
    }
  },
  {
    "instruction": "Calculate the Hinge loss for a binary classification problem.",
    "function_call": {
      "name": "hinge_loss_binary_classification"
    }
  },
  {
    "instruction": "Perform feature selection using LASSO regression for feature importance.",
    "function_call": {
      "name": "lasso_regression_feature_selection"
    }
  },
  {
    "instruction": "Visualize the model's performance with precision, recall, and F1-score over epochs.",
    "function_call": {
      "name": "performance_metrics_epochs"
    }
  },
  {
    "instruction": "Calculate the Hellinger distance between probability distributions.",
    "function_call": {
      "name": "hellinger_distance_probability_distributions"
    }
  },
  {
    "instruction": "Train a model with dropout regularization to prevent overfitting.",
    "function_call": {
      "name": "dropout_regularization_model"
    }
  },
  {
    "instruction": "Visualize the model's learning rate over epochs.",
    "function_call": {
      "name": "learning_rate_history"
    }
  },
  {
    "instruction": "Calculate the entropy for a set of categorical features.",
    "function_call": {
      "name": "entropy_categorical_features"
    }
  },
  {
    "instruction": "Perform data sampling to balance classes in an imbalanced dataset.",
    "function_call": {
      "name": "imbalance_data_sampling"
    }
  },
  {
    "instruction": "Visualize the feature importances using a sunburst chart with categories.",
    "function_call": {
      "name": "sunburst_chart_feature_importance"
    }
  },
  {
    "instruction": "Calculate the AIC and BIC for model selection.",
    "function_call": {
      "name": "aic_bic_model_selection"
    }
  },
  {
    "instruction": "Train a model using a custom activation function.",
    "function_call": {
      "name": "model_custom_activation_function"
    }
  },
  {
    "instruction": "Visualize the model's feature contributions using SHAP values in a waterfall chart.",
    "function_call": {
      "name": "shap_values_waterfall_chart"
    }
  },
  {
    "instruction": "Calculate the Matthews correlation coefficient for binary classification.",
    "function_call": {
      "name": "matthews_correlation_coefficient_binary"
    }
  },
  {
    "instruction": "Get an overview of the data including number of rows, columns, and basic statistics.",
    "function_call": {
      "name": "data_description",
      "arguments": {}
    }
  },
  {
    "instruction": "Display the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete a column named 'unnecessary_column' from the dataset.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_column"
      }
    }
  },
  {
    "instruction": "Delete rows at indices 0, 1, and 2.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          0,
          1,
          2
        ]
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the data into 80% training and 20% testing sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode categorical column 'species' ordinally.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "species"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'color' column.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "color"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model on the dataset.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) for classification.",
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a linear regression model for predicting house prices.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Draw a correlation matrix to visualize feature relationships.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a neural network for a classification task.",
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an XGBoost classifier.",
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a bagging classifier ensemble.",
    "function_call": {
      "name": "bagging_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Extract task and target from the dataset information.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Select important features using mutual information criterion.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "10"
      }
    }
  },
  {
    "instruction": "Normalize the 'height' and 'weight' columns to a range of 0 to 1.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "height,weight"
      }
    }
  },
  {
    "instruction": "Impute missing values in 'age' with the mean.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce dimensions to 2.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data with a test size of 20%.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Generate interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureA','featureB')"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of the logistic regression model on train and test sets.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression_model"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the SVM model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svc",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Generate a confusion matrix plot for the decision tree model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the random forest model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in the 'salary' column using IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr"
      }
    }
  },
  {
    "instruction": "Load the saved logistic regression model.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "logistic_regression_model.pkl"
      }
    }
  },
  {
    "instruction": "Check for class imbalance in the 'classification_dataset'.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {}
    }
  },
  {
    "instruction": "Scale 'featureX' and 'featureY' columns using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Treat detected outliers in 'age' by replacing them with the median.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "median",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Sample 80% of the dataset for downsampling.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "downsampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'feature1' and 'feature2' to create a new feature.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "instruction": "Iteratively eliminate features using backward elimination.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "instruction": "Forecast sales for the next 3 months using ARIMA.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "3"
      }
    }
  },
  {
    "instruction": "Interpret the predictions of the random forest model.",
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "random_forest_classifier",
        "instance_id": "123"
      }
    }
  },
  {
    "instruction": "Anonymize the 'personal_info' column to protect privacy.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize 'age' into 5 equal-frequency bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_frequency",
        "bins": "5"
      }
    }
  },
  {
    "instruction": "Increase dataset size with rotation augmentation.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "rotation"
      }
    }
  },
  {
    "instruction": "Visualize pairwise relationships among 'featureA', 'featureB', and 'featureC'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "featureA,featureB,featureC",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Analyze the complexity of the decision tree model.",
    "function_call": {
      "name": "model_complexity_analysis",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Apply log transformation to 'income' to handle skewness.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "income"
      }
    }
  },
  {
    "instruction": "Transform text data using TF-IDF with 1000 features.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000"
      }
    }
  },
  {
    "instruction": "Split dataset into 5 folds for cross-validation.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Optimize hyperparameters for the random forest model using grid search.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "random_forest_classifier",
        "param_grid": {
          "n_estimators": [
            10,
            50,
            100
          ],
          "max_depth": [
            "None",
            10,
            20
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate the recall score for the trained random forest model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Calculate the precision score for the logistic regression model.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared error for the linear regression model.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the R-squared score for the trained regression model.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the Mean Absolute Error for the regression model.",
    "function_call": {
      "name": "mean absolute error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Perform a residual analysis for the regression model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression",
        "predictions": "predicted_values",
        "actuals": "actual_values"
      }
    }
  },
  {
    "instruction": "Calculate prediction intervals for the regression model.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "linear_regression",
        "data": "new_data",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize regression coefficients and their significance.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Assess multicollinearity among predictors using VIF.",
    "function_call": {
      "name": "regression_multicollinearity_vif",
      "arguments": {
        "data": "predictor_variables"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Process Regression model.",
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF"
      }
    }
  },
  {
    "instruction": "Train a Bayesian Ridge Regression model.",
    "function_call": {
      "name": "bayesian_ridge_regression",
      "arguments": {
        "alpha_1": "0.1",
        "alpha_2": "0.1"
      }
    }
  },
  {
    "instruction": "Fit a polynomial regression model of degree 3.",
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "3"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence of the random forest model on 'featureX' and 'featureY'.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "random_forest_classifier",
        "features": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Apply exponential smoothing with a multiplicative seasonal component.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "mul",
        "damped": true
      }
    }
  },
  {
    "instruction": "Train a multiple linear regression model with 'feature1', 'feature2', and 'feature3'.",
    "function_call": {
      "name": "multiple_linear_regression",
      "arguments": {
        "predictors": "feature1,feature2,feature3"
      }
    }
  },
  {
    "instruction": "Train a Naive Bayes classifier with the Gaussian distribution.",
    "function_call": {
      "name": "naive_bayes_classifier",
      "arguments": {
        "algo": "gaussian"
      }
    }
  },
  {
    "instruction": "Perform spectral clustering with 3 clusters.",
    "function_call": {
      "name": "spectral_clustering",
      "arguments": {
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Fit a Gaussian Mixture Model with 4 components.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Cluster data using a Random Forest's feature importance.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Combine multiple classifiers into a voting classifier.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['classifier1', 'classifier2', 'classifier3']",
        "voting": "hard"
      }
    }
  },
  {
    "instruction": "Use Stochastic Gradient Descent for optimization.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "constant",
        "loss": "hinge"
      }
    }
  },
  {
    "instruction": "Optimize with Adaptive Moment Estimation (Adam).",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Apply RMSprop for efficient optimization.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.01",
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Use Adagrad for adaptive learning rate optimization.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ Nesterov Accelerated Gradient for training.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Utilize L-BFGS for optimization.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Use basic Gradient Descent for optimization.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Save the trained model as 'my_model.pkl'.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "filename": "my_model.pkl",
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Evaluate model performance on unseen data.",
    "function_call": {
      "name": "evaluate_model",
      "arguments": {
        "model": "trained_model",
        "test_data": "test_set"
      }
    }
  },
  {
    "instruction": "Perform feature importance analysis on the trained model.",
    "function_call": {
      "name": "analyze_feature_importance",
      "arguments": {
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Apply feature selection to reduce dimensionality.",
    "function_call": {
      "name": "select_features",
      "arguments": {
        "method": "mutual_info",
        "num_features": "10"
      }
    }
  },
  {
    "instruction": "Visualize the decision boundaries of a classifier.",
    "function_call": {
      "name": "plot_decision_boundaries",
      "arguments": {
        "model": "classifier",
        "data": "training_data",
        "labels": "training_labels"
      }
    }
  },
  {
    "instruction": "Balance the dataset using SMOTE.",
    "function_call": {
      "name": "balance_dataset",
      "arguments": {
        "method": "smote"
      }
    }
  },
  {
    "instruction": "Apply Principal Component Analysis for dimensionality reduction.",
    "function_call": {
      "name": "apply_pca",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix to visualize pair-wise relationships.",
    "function_call": {
      "name": "scatter_plot_matrix",
      "arguments": {
        "data": "dataset",
        "features": "[feature1, feature2, feature3]"
      }
    }
  },
  {
    "instruction": "Implement K-means clustering with 5 clusters.",
    "function_call": {
      "name": "kmeans_clustering",
      "arguments": {
        "clusters": "5"
      }
    }
  },
  {
    "instruction": "Calculate F1 score for the classification model.",
    "function_call": {
      "name": "calculate_f1_score",
      "arguments": {
        "model": "classification_model",
        "y_true": "true_labels",
        "y_pred": "predicted_labels"
      }
    }
  },
  {
    "instruction": "Train a K-Nearest Neighbors classifier with 5 neighbors.",
    "function_call": {
      "name": "train_knn_classifier",
      "arguments": {
        "n_neighbors": "5"
      }
    }
  },
  {
    "instruction": "Create a pipeline with standardization and logistic regression.",
    "function_call": {
      "name": "create_pipeline",
      "arguments": {
        "steps": [
          "standardization",
          "logistic_regression"
        ]
      }
    }
  },
  {
    "instruction": "Visualize the ROC curve for the binary classification model.",
    "function_call": {
      "name": "plot_roc_curve",
      "arguments": {
        "model": "binary_classifier",
        "y_true": "true_labels",
        "y_pred_proba": "predicted_probabilities"
      }
    }
  },
  {
    "instruction": "Apply data augmentation to increase the image dataset size.",
    "function_call": {
      "name": "augment_images",
      "arguments": {
        "method": "horizontal_flip",
        "dataset": "image_data"
      }
    }
  },
  {
    "instruction": "Analyze lift charts for a predictive model.",
    "function_call": {
      "name": "plot_lift_chart",
      "arguments": {
        "model": "predictive_model",
        "data": "sample_data"
      }
    }
  },
  {
    "instruction": "Calculate the area under the Precision-Recall curve.",
    "function_call": {
      "name": "precision_recall_curve",
      "arguments": {
        "model": "classifier",
        "y_true": "ground_truth",
        "y_scores": "predicted_scores"
      }
    }
  },
  {
    "instruction": "Visualize the cluster centers for KMeans.",
    "function_call": {
      "name": "plot_cluster_centers",
      "arguments": {
        "model": "kmeans_model"
      }
    }
  },
  {
    "instruction": "Apply PCA for visualization with 2 principal components.",
    "function_call": {
      "name": "visualize_with_pca",
      "arguments": {
        "components": "2",
        "data": "reduced_data"
      }
    }
  },
  {
    "instruction": "Compute the silhouette score for clustering evaluation.",
    "function_call": {
      "name": "silhouette_score",
      "arguments": {
        "model": "clustering_model",
        "data": "clustered_data"
      }
    }
  },
  {
    "instruction": "Evaluate model stability with permutation feature importance.",
    "function_call": {
      "name": "permute_feature_importance",
      "arguments": {
        "model": "trained_model",
        "data": "feature_data",
        "labels": "target_labels"
      }
    }
  },
  {
    "instruction": "Create a stacked ensemble of multiple models.",
    "function_call": {
      "name": "stack_models",
      "arguments": {
        "base_models": [
          "model1",
          "model2",
          "model3"
        ],
        "meta_model": "meta_model_type"
      }
    }
  },
  {
    "instruction": "Estimate feature importances using permutation test.",
    "function_call": {
      "name": "permutation_importance",
      "arguments": {
        "model": "trained_model",
        "data": "feature_matrix",
        "labels": "target"
      }
    }
  },
  {
    "instruction": "Generate synthetic data for imbalanced classes.",
    "function_call": {
      "name": "generate_synthetic_data",
      "arguments": {
        "imbalance_ratio": "0.1",
        "num_samples": "1000"
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce the dimensionality of the data to 5 principal components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "5"
      }
    }
  },
  {
    "instruction": "Check for class imbalance in the classification datasets.",
    "function_call": {
      "name": "data_balance_check"
    }
  },
  {
    "instruction": "Visualize the distribution of feature 'age' using histograms with 10 bins.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age",
        "bins": "10"
      }
    }
  },
  {
    "instruction": "Evaluate the accuracy of the trained model 'lr_model' on the test set.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "lr_model"
      }
    }
  },
  {
    "instruction": "Impute missing values in the dataset using the mean strategy.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix to visualize pairwise relationships among 'feature1', 'feature2', and 'feature3'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3",
        "hue": "label"
      }
    }
  },
  {
    "instruction": "Standardize the columns 'height', 'weight', and 'age' in the dataset.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "height,weight,age"
      }
    }
  },
  {
    "instruction": "Encode categorical columns 'category1' and 'category2' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category1,category2"
      }
    }
  },
  {
    "instruction": "Delete the rows at indices 0, 5, and 10 from the dataset.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": "[0, 5, 10]"
      }
    }
  },
  {
    "instruction": "Split the data into 80% training and 20% testing sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Apply Min-Max scaling to the columns 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Detect outliers in the 'salary' column using the IQR method with a threshold of 1.5.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Extract the task and target from the dataset information, assuming the target is 'target_column'.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Create a polynomial feature from 'featureX' and 'featureY' with degree 2.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "featureX,featureY",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model with the 'balanced' class weight.",
    "function_call": {
      "name": "logistic_regression"
    }
  },
  {
    "instruction": "Anonymize the 'personal_info' column using k-anonymity with k=5.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Extract the most important features using the 'rf_feature_importance' method with the top 10 features.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "rf_feature_importance",
        "k": "10"
      }
    }
  },
  {
    "instruction": "Train a neural network classifier with 2 hidden layers.",
    "function_call": {
      "name": "neural_network_classifier"
    }
  },
  {
    "instruction": "Perform k-fold cross-validation with 5 folds on the 'svm_model'.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svm_model",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for the 'dt_classifier' model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "dt_classifier"
      }
    }
  },
  {
    "instruction": "Evaluate the model using the F1 score.",
    "function_call": {
      "name": "recall_score"
    }
  },
  {
    "instruction": "Load the saved model from 'model_best.sav'.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "model_best.sav"
      }
    }
  },
  {
    "instruction": "Create a custom preprocessing pipeline with steps 'standardization', 'feature_selection', and 'train_test_split'.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "standardization, feature_selection, datasets_split"
      }
    }
  },
  {
    "instruction": "Apply the 'elastic_net_regression' with an alpha of 0.1 and l1_ratio of 0.5.",
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.1",
        "l1_ratio": "0.5"
      }
    }
  },
  {
    "instruction": "Generate synthetic samples for data augmentation using the 'rotation' method.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "rotation"
      }
    }
  },
  {
    "instruction": "Perform a grid search for hyperparameter tuning on the 'rf_model' with different 'n_estimators' and 'max_depth' values.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "rf_model",
        "param_grid": {
          "n_estimators": [
            100,
            200
          ],
          "max_depth": [
            "None",
            10,
            20
          ]
        }
      }
    }
  },
  {
    "instruction": "Draw a correlation matrix to understand feature relationships.",
    "function_call": {
      "name": "correlation_matrix"
    }
  },
  {
    "instruction": "Train a Gaussian Naive Bayes classifier.",
    "function_call": {
      "name": "naive_bayes_classifier",
      "arguments": {
        "algo": "gaussian"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the 'rf_model' and select the top 5.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "rf_feature_importance",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Use DBSCAN with eps=0.3 and min_samples=5 for clustering.",
    "function_call": {
      "name": "dbscan",
      "arguments": {
        "eps": "0.3",
        "min_samples": "5"
      }
    }
  },
  {
    "instruction": "Create a pipeline combining 'data_normalization' and 'random_forest_classifier'.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "data_normalization, random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Process Regression with an RBF kernel.",
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared error for the 'lr_regression_model' predictions.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "lr_regression_model"
      }
    }
  },
  {
    "instruction": "Calculate the R-squared value for the 'ridge_regression_model'.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "ridge_regression_model"
      }
    }
  },
  {
    "instruction": "Plot the learning curves of the 'svc_model' to analyze bias-variance tradeoff.",
    "function_call": {
      "name": "model_complexity_analysis",
      "arguments": {
        "model": "svc_model"
      }
    }
  },
  {
    "instruction": "Create a decision tree classifier with a maximum depth of 3.",
    "function_call": {
      "name": "decision_tree_classifier"
    }
  },
  {
    "instruction": "Evaluate the precision score of the 'mlp_classifier'.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "mlp_classifier"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to categorical columns 'categoryA', 'categoryB'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categoryA,categoryB"
      }
    }
  },
  {
    "instruction": "Use Lasso Regression with an alpha of 0.01.",
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.01"
      }
    }
  },
  {
    "instruction": "Visualize the residual plot for the 'linear_regression_model'.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression_model"
      }
    }
  },
  {
    "instruction": "Perform exponential smoothing for time series forecasting with a trend component.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "none",
        "damped": "false"
      }
    }
  },
  {
    "instruction": "Combine the predictions of 'model1', 'model2', and 'model3' using a soft voting ensemble.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "model1,model2,model3",
        "voting": "soft"
      }
    }
  },
  {
    "instruction": "Train an XGBoost classifier with 100 estimators.",
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {
        "n_estimators": "100"
      }
    }
  },
  {
    "instruction": "Detect and remove outliers from 'featureZ' using Z-score with a threshold of 3.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "zscore",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Apply a logarithmic transformation to 'price' to handle skewness.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "price"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Mixture Model with 3 clusters.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "3"
      }
    }
  },
  {
    "instruction": "Use the 'adam' optimizer with a learning rate of 0.001 for model optimization.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Calculate the mean absolute error for the 'gradient_boosting_regression' model.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "gradient_boosting_regression"
      }
    }
  },
  {
    "instruction": "Perform a principal component analysis and retain 95% of variance.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "95%"
      }
    }
  },
  {
    "instruction": "Apply the Box-Cox transformation to normalize columns 'feature1,feature2'.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Select the top 10 features based on mutual information for regression.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "10"
      }
    }
  },
  {
    "instruction": "Use RFE with a linear regression model to select 7 features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "linear_regression",
        "num_features": "7"
      }
    }
  },
  {
    "instruction": "Train a Gradient Boosting Regression model with a learning rate of 0.1.",
    "function_call": {
      "name": "gradient_boosting_regression",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC for the model 'gbm_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "gbm_model"
      }
    }
  },
  {
    "instruction": "Remove duplicate rows from the dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression model with alpha=0.5 and a 'linear' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.5",
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Apply the Box-Cox transformation to 'income' and 'age' columns.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "income,age"
      }
    }
  },
  {
    "instruction": "Select 5 top features using mutual information for a regression problem.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Use RFE with an SVC model to select 3 best features for classification.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "svc",
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC for the logistic regression model 'lr_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "lr_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates considering all columns in the dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with alpha=1.0 and 'rbf' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "1.0",
        "kernel": "rbf"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to numeric columns 'featureX,featureY' for normalization.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Select the top 8 features for regression using mutual information criterion.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "8"
      }
    }
  },
  {
    "instruction": "Perform RFE with a decision tree model to select 4 features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "decision_tree",
        "num_features": "4"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC of the random forest classifier 'rfc_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "rfc_model"
      }
    }
  },
  {
    "instruction": "Remove duplicate rows based on 'timestamp' and 'id' columns.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with a 'poly' kernel and alpha=0.01.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.01",
        "kernel": "poly"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox to 'columnA' and 'columnB' for better regression analysis.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "columnA,columnB"
      }
    }
  },
  {
    "instruction": "Select 6 most informative features using mutual information for regression.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "6"
      }
    }
  },
  {
    "instruction": "Use RFE with a Ridge regression model to select 5 key features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "ridge_regression",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC for a support vector machine classifier 'svm_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "svm_model"
      }
    }
  },
  {
    "instruction": "Clean dataset by removing all duplicate entries.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge model with alpha=0.2 and a 'sigmoid' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.2",
        "kernel": "sigmoid"
      }
    }
  },
  {
    "instruction": "Box-Cox transform 'duration' and 'distance' columns for regression prep.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "duration,distance"
      }
    }
  },
  {
    "instruction": "Select top 3 features using mutual information for regression tasks.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "RFE with 'linear_regression' to select 2 most predictive features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "linear_regression",
        "num_features": "2"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC for the 'xgboost_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "xgboost_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the dataset without considering the 'ID' column.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with alpha=0.5 and 'linear' kernel for a smooth fit.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.5",
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'featureZ' to address skewness.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "featureZ"
      }
    }
  },
  {
    "instruction": "Select 4 most informative features for regression via mutual information.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "4"
      }
    }
  },
  {
    "instruction": "RFE with 'svc' to select 6 features for classification.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "svc",
        "num_features": "6"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC for the 'knn_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "knn_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates from the dataset, considering all columns for uniqueness.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with an 'rbf' kernel and alpha=0.1 for non-linear fitting.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.1",
        "kernel": "rbf"
      }
    }
  },
  {
    "instruction": "Transform 'feature_set1' using Box-Cox for improved regression analysis.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "feature_set1"
      }
    }
  },
  {
    "instruction": "Select top 7 features using mutual information for regression.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "7"
      }
    }
  },
  {
    "instruction": "RFE with 'gradient_boosting' to pick 8 best features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "gradient_boosting",
        "num_features": "8"
      }
    }
  },
  {
    "instruction": "ROC AUC assessment for 'lightgbm_model'.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "lightgbm_model"
      }
    }
  },
  {
    "instruction": "Efficiently remove duplicate rows across the entire dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with a 'poly' kernel and alpha=0.05 for complex relations.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.05",
        "kernel": "poly"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox to 'featureA' and 'featureB' columns for standardization.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Select the top 5 features using mutual information criterion for a regression study.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "RFE with a 'random_forest' model to select 3 critical features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "random_forest",
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC for the 'logistic_model' to assess classification performance.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "logistic_model"
      }
    }
  },
  {
    "instruction": "Remove duplicate rows from the dataset while preserving the first occurrence.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Use a 'sigmoid' kernel in Kernel Ridge Regression with alpha=0.3.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.3",
        "kernel": "sigmoid"
      }
    }
  },
  {
    "instruction": "Transform 'temperature' and 'humidity' with Box-Cox for better regression modeling.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "temperature,humidity"
      }
    }
  },
  {
    "instruction": "Select 4 most predictive features for 'regression_task' using mutual information.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "4"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the dataset based on 'unique_id' column.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with 'poly' kernel for complex non-linear data with alpha=0.1.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.1",
        "kernel": "poly"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'sales_data' column for better linearity.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "sales_data"
      }
    }
  },
  {
    "instruction": "Select the top 6 features for 'classification' task using RFE with a 'svm' model.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "svm",
        "num_features": "6"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC of the 'svc_model' for binary classification.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "svc_model"
      }
    }
  },
  {
    "instruction": "Remove all duplicate rows considering all columns for 'clean_data' dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Use 'linear' kernel in Kernel Ridge Regression for a simple regression analysis with alpha=0.05.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.05",
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Transform 'time_series_features' using Box-Cox to stabilize variance.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "time_series_features"
      }
    }
  },
  {
    "instruction": "Select top 5 features based on mutual information for a 'regression_study' dataset.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Perform Recursive Feature Elimination with a 'linear_regression' model to choose 3 features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "linear_regression",
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "Evaluate the model's ROC AUC for 'rf_classifier_model' on the test set.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "rf_classifier_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the dataset, excluding the 'date' column.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with a 'rbf' kernel to capture non-linearities, alpha=0.2.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.2",
        "kernel": "rbf"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'feature_group1' to improve normality.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "feature_group1"
      }
    }
  },
  {
    "instruction": "Select 7 most informative features for regression analysis using mutual information criterion.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "7"
      }
    }
  },
  {
    "instruction": "Use RFE with a 'random_forest' estimator to select 4 features for classification.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "random_forest",
        "num_features": "4"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC for the 'gradient_boost' model to assess its discriminative power.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "gradient_boost"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the 'survey_data' considering all columns except 'respondent_id'.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with 'sigmoid' kernel for advanced feature interaction, alpha=0.01.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.01",
        "kernel": "sigmoid"
      }
    }
  },
  {
    "instruction": "Transform 'numeric_features' with Box-Cox for improved linear regression assumptions.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "numeric_features"
      }
    }
  },
  {
    "instruction": "Select top 8 features using mutual information for 'customer_behavior' regression model.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "8"
      }
    }
  },
  {
    "instruction": "RFE feature selection with a 'logistic_regression' model to pick 5 features.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "logistic_regression",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Evaluate the ROC AUC of the 'nb_model' for binary classification accuracy.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "nb_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the 'survey_results' dataset based on unique respondent characteristics.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Use a 'linear' kernel in Kernel Ridge Regression for straightforward regression, alpha=0.5.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.5",
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'economic_index' to normalize data for regression.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "economic_index"
      }
    }
  },
  {
    "instruction": "Select 3 most significant features using mutual information for a 'health_study' regression analysis.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "RFE with a 'decision_tree' model to select 6 features for a classification problem.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "decision_tree",
        "num_features": "6"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC for 'knn_classifier' to measure classification effectiveness.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "knn_classifier"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the 'sales_records' dataset, focusing on transaction IDs.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with 'poly' kernel, exploring higher-order interactions, alpha=0.1.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.1",
        "kernel": "poly"
      }
    }
  },
  {
    "instruction": "Transform 'sensor_readings' using Box-Cox for stabilizing the variance.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "sensor_readings"
      }
    }
  },
  {
    "instruction": "Select top 9 features for 'weather_prediction' task using mutual information.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "9"
      }
    }
  },
  {
    "instruction": "RFE with 'gradient_boosting' model to select optimal 7 features for regression.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "gradient_boosting",
        "num_features": "7"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC of the 'dt_classifier' to assess classification performance.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "dt_classifier"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the 'marketing_data' after considering 'campaign_date' and 'customer_id'.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Use 'rbf' kernel in Kernel Ridge Regression for complex patterns, alpha=0.005.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.005",
        "kernel": "rbf"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox to 'stock_prices' for better stationarity in time series analysis.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "stock_prices"
      }
    }
  },
  {
    "instruction": "Select top 2 features using mutual information for 'customer_segmentation' regression model.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "2"
      }
    }
  },
  {
    "instruction": "RFE with 'linear_svc' for selecting 4 best features in a binary classification task.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "linear_svc",
        "num_features": "4"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC of 'ensemble_model' to quantify model discrimination.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "ensemble_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates in the 'patient_records' dataset, preserving the earliest record.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with a 'sigmoid' kernel, fine-tuned for specific data, alpha=0.3.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.3",
        "kernel": "sigmoid"
      }
    }
  },
  {
    "instruction": "Transform 'environmental_factors' with Box-Cox to improve model assumptions.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "environmental_factors"
      }
    }
  },
  {
    "instruction": "Select top 6 features using mutual information for 'credit_risk' classification.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "6"
      }
    }
  },
  {
    "instruction": "RFE with 'ridge_regression' to identify 5 essential features for prediction.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "ridge_regression",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Evaluate ROC AUC for 'svm_rbf_model' to assess its performance in a classification scenario.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "svm_rbf_model"
      }
    }
  },
  {
    "instruction": "Remove duplicates from 'product_sales_data' ensuring uniqueness based on 'sku' and 'sale_date'.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Kernel Ridge Regression with a 'linear' kernel for a simple yet effective regression, alpha=0.05.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "alpha": "0.05",
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Get the overview of the data.",
    "function_call": {
      "name": "data_description",
      "arguments": {}
    }
  },
  {
    "instruction": "Show the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete the column named 'unnecessary_column'.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_column"
      }
    }
  },
  {
    "instruction": "Delete rows at indices 0, 1, and 2.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          0,
          1,
          2
        ]
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the data into 80% for training and 20% for testing.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode the 'category' column using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'gender' and 'occupation'.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "gender,occupation"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) for classification.",
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a linear regression model.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Draw a correlation matrix for the dataset.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a neural network for a classification task.",
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an XGBoost classifier.",
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Specify the task as classification with 'target_column' as the target.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Select important features using mutual information.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "10"
      }
    }
  },
  {
    "instruction": "Normalize the 'height' and 'weight' columns.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "height,weight"
      }
    }
  },
  {
    "instruction": "Impute missing values in the dataset with the mean.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce dimensions to 3.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "3"
      }
    }
  },
  {
    "instruction": "Split time series data with a test size of 20%.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureX' and 'featureY'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureX','featureY')"
      }
    }
  },
  {
    "instruction": "Evaluate the accuracy of the logistic regression model on train and test sets.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the decision tree classifier.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "decision_tree_classifier",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for the random forest model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the gradient boosting model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "gradient_boosting_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers using IQR method in the 'age' column.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Load the saved 'my_best_model'.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "my_best_model"
      }
    }
  },
  {
    "instruction": "Check for class balance in the 'classification_task' dataset.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {
        "task": "classification_task"
      }
    }
  },
  {
    "instruction": "Scale 'featureA' and 'featureB' using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "instruction": "Treat outliers in 'salary' column by capping.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Sample 80% of the dataset for size reduction.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'feature1' and 'feature2' to create 'new_feature'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "instruction": "Eliminate features using backward elimination with 'accuracy' as the metric.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "instruction": "Forecast future sales using ARIMA with a horizon of 6 months.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "6"
      }
    }
  },
  {
    "instruction": "Interpret the predictions of the random forest model.",
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "random_forest_classifier",
        "instance_id": "123"
      }
    }
  },
  {
    "instruction": "Anonymize personal data using 'k_anonymity' with k=5.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Discretize the 'age' feature into 5 bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "age"
      }
    }
  },
  {
    "instruction": "Increase dataset size with random sampling.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "random_sampling"
      }
    }
  },
  {
    "instruction": "Decompose the 'sales_data' into trend, seasonality, and residuals.",
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "additive",
        "data": "sales_data"
      }
    }
  },
  {
    "instruction": "Stack multiple models for ensemble learning.",
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": "model1,model2",
        "meta_model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Enrich the dataset with external data from 'external_dataset_url'.",
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "external_dataset_url"
      }
    }
  },
  {
    "instruction": "Create a preprocessing pipeline with data normalization and feature scaling.",
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "[data_normalization, feature_scaling_minmax]"
      }
    }
  },
  {
    "instruction": "Train a K-Nearest Neighbors classifier with 5 neighbors.",
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "5"
      }
    }
  },
  {
    "instruction": "Calculate the ROC AUC score for the SVM model.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "instruction": "Remove duplicate rows from the data.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal",
      "arguments": {}
    }
  },
  {
    "instruction": "Transform text data into TF-IDF features with 1000 features.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000"
      }
    }
  },
  {
    "instruction": "Split dataset into 5 folds for cross-validation.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Tune hyperparameters for the linear regression model using grid search.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "linear_regression",
        "param_grid": {
          "alpha": [
            0.01,
            0.1,
            1.0
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate the recall score for the 'random_forest' model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Calculate the precision score for the 'svm' model.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "instruction": "Calculate the mean squared error for the 'linear_regression' model.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the R-squared score for the 'random_forest_regression' model.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "random_forest_regression"
      }
    }
  },
  {
    "instruction": "Calculate the mean absolute error for the 'elastic_net_regression' model.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "elastic_net_regression"
      }
    }
  },
  {
    "instruction": "Analyze residuals for the 'ridge_regression' model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "ridge_regression",
        "predictions": "predicted_values",
        "actuals": "actual_values"
      }
    }
  },
  {
    "instruction": "Generate prediction intervals for 'polynomial_regression' at 95% confidence.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "polynomial_regression",
        "data": "new_data",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize regression coefficients for the 'multiple_linear_regression' model.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "multiple_linear_regression"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'feature1' and 'feature2' in the 'gradient_boosting' model.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "gradient_boosting_classifier",
        "features": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Forecast sales with exponential smoothing, considering trend and multiplicative seasonality.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "mul"
      }
    }
  },
  {
    "instruction": "Cluster data using Gaussian Mixture Model with 3 components.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "3"
      }
    }
  },
  {
    "instruction": "Cluster data using Random Forest Clustering with 4 clusters.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "4"
      }
    }
  },
  {
    "instruction": "Combine multiple classifiers into a voting ensemble with soft voting.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['svc', 'random_forest_classifier', 'logistic_regression']",
        "voting": "soft"
      }
    }
  },
  {
    "instruction": "Use Stochastic Gradient Descent with a learning rate of 0.01.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Optimize model with Adam optimizer and a learning rate of 0.001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Apply RMSprop optimization with a learning rate of 0.005.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.005",
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Use Adagrad with a learning rate of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Optimize with Nesterov's Accelerated Gradient with a learning rate of 0.01.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ L-BFGS for optimization.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Standardize data across all columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "all"
      }
    }
  },
  {
    "instruction": "Visualize data correlations using a heatmap.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {
        "visualize": "true"
      }
    }
  },
  {
    "instruction": "Create a decision tree with a maximum depth of 5.",
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {
        "max_depth": "5"
      }
    }
  },
  {
    "instruction": "Implement PCA for dimensionality reduction, retaining 95% variance.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "0.95"
      }
    }
  },
  {
    "instruction": "Use 'knn' for imputation with 3 nearest neighbors.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "knn",
        "value": "3"
      }
    }
  },
  {
    "instruction": "Balance the dataset using SMOTE oversampling.",
    "function_call": {
      "name": "data_balance_check",
      "arguments": {
        "method": "smote"
      }
    }
  },
  {
    "instruction": "Create a polynomial feature from 'feature1' of degree 3.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1",
        "degree": "3"
      }
    }
  },
  {
    "instruction": "Plot the feature importance for the 'random_forest' model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'featureX' using Z-score with a threshold of 3.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "zscore",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Save the trained 'svm' model.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "model": "svm",
        "filename": "svm_model.pkl"
      }
    }
  },
  {
    "instruction": "Evaluate the model using F1 score.",
    "function_call": {
      "name": "evaluate_model",
      "arguments": {
        "metric": "f1",
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Visualize the decision boundaries of the 'svm' classifier.",
    "function_call": {
      "name": "plot_decision_boundaries",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "instruction": "Calculate feature importances for regression using permutation importance.",
    "function_call": {
      "name": "feature_importance_permutation",
      "arguments": {
        "model": "random_forest_regression",
        "data": "data",
        "target": "target"
      }
    }
  },
  {
    "instruction": "Perform anomaly detection with Isolation Forest.",
    "function_call": {
      "name": "anomaly_detection_isolation_forest",
      "arguments": {
        "contamination": "0.1"
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix for feature exploration.",
    "function_call": {
      "name": "scatter_plot_matrix",
      "arguments": {
        "features": "feature1,feature2,feature3"
      }
    }
  },
  {
    "instruction": "Fit a KMeans clustering model with 5 clusters.",
    "function_call": {
      "name": "kmeans",
      "arguments": {
        "clusters": "5"
      }
    }
  },
  {
    "instruction": "Calculate the silhouette score for the KMeans clustering.",
    "function_call": {
      "name": "silhouette_score",
      "arguments": {
        "model": "kmeans",
        "data": "data"
      }
    }
  },
  {
    "function_call": {
      "name": "data_description",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "column_to_delete"
      }
    }
  },
  {
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3"
      }
    }
  },
  {
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category_column"
      }
    }
  },
  {
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categorical_columns"
      }
    }
  },
  {
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "random_forest_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "bagging_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "ada_boost_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "gradient_boosting_classifier",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "norm_columns"
      }
    }
  },
  {
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean"
      }
    }
  },
  {
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureA','featureB')"
      }
    }
  },
  {
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svc",
        "folds": "10"
      }
    }
  },
  {
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "gradient_boosting_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "model.pkl"
      }
    }
  },
  {
    "function_call": {
      "name": "data_balance_check",
      "arguments": {
        "task": "classification"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "featureA,featureB"
      }
    }
  },
  {
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "3"
      }
    }
  },
  {
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.7"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "random_forest_classifier",
        "instance_id": "123"
      }
    }
  },
  {
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity",
        "k": "3"
      }
    }
  },
  {
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "age"
      }
    }
  },
  {
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "rotation"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_seasonality_decomposition",
      "arguments": {
        "model": "additive",
        "data": "time_series_data"
      }
    }
  },
  {
    "function_call": {
      "name": "ensemble_stacking",
      "arguments": {
        "level_models": "model1,model2",
        "meta_model": "logistic_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "url1,url2"
      }
    }
  },
  {
    "function_call": {
      "name": "data_preprocessing_pipeline",
      "arguments": {
        "steps": "[data_normalization, feature_scaling_minmax]"
      }
    }
  },
  {
    "function_call": {
      "name": "ensemble_nearest_neighbors_classification",
      "arguments": {
        "n_neighbors": "7"
      }
    }
  },
  {
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "svc"
      }
    }
  },
  {
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "random_forest_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "elastic_net_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "ridge_regression",
        "predictions": "predicted",
        "actuals": "actual"
      }
    }
  },
  {
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "polynomial_regression",
        "data": "new_data",
        "confidence_level": "0.9"
      }
    }
  },
  {
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "multiple_linear_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "gradient_boosting",
        "features": "feature1,feature2"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "mul"
      }
    }
  },
  {
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "3"
      }
    }
  },
  {
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "4"
      }
    }
  },
  {
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['svc', 'random_forest', 'logistic_regression']",
        "voting": "hard"
      }
    }
  },
  {
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "loss": "hinge"
      }
    }
  },
  {
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.0001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "rho": "0.9"
      }
    }
  },
  {
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "momentum": "0.9"
      }
    }
  },
  {
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_col1,unnecessary_col2"
      }
    }
  },
  {
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "categorical_col1,categorical_col2"
      }
    }
  },
  {
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categorical_col3"
      }
    }
  },
  {
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "3"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.1"
      }
    }
  },
  {
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "featureA,featureB",
        "degree": "2"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureC','featureD')"
      }
    }
  },
  {
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svc",
        "folds": "10"
      }
    }
  },
  {
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "xgb_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age_distribution"
      }
    }
  },
  {
    "function_call": {
      "name": "data_enrichment",
      "arguments": {
        "source_urls": "data_source1.csv, data_source2.csv"
      }
    }
  },
  {
    "function_call": {
      "name": "data_cleaning_duplicate_removal",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000",
        "text_column": "text"
      }
    }
  },
  {
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5",
        "shuffle": "true"
      }
    }
  },
  {
    "function_call": {
      "name": "model_tuning_random_search",
      "arguments": {
        "model": "random_forest",
        "param_grid": "param_grid_dict"
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "random_forest_classifier",
        "data": "test_set"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "positive_numeric_cols"
      }
    }
  },
  {
    "function_call": {
      "name": "data_discretization_quantile_bins",
      "arguments": {
        "columns": "continuous_cols",
        "bins": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['lr', 'rf', 'svm']",
        "voting": "hard"
      }
    }
  },
  {
    "function_call": {
      "name": "data_balance_smote",
      "arguments": {
        "minority_class": "rare_class"
      }
    }
  },
  {
    "function_call": {
      "name": "data_augmentation_image_rotate",
      "arguments": {
        "angle_range": "10-20",
        "image_column": "image"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_standard_scaler_all",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "mul",
        "seasonal": "add",
        "damped": "true"
      }
    }
  },
  {
    "function_call": {
      "name": "random_forest_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "gradient_boosting_regression",
      "arguments": {}
    }
  },
  {
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.1",
        "l1_ratio": "0.5"
      }
    }
  },
  {
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.01"
      }
    }
  },
  {
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "1.0"
      }
    }
  },
  {
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF",
        "alpha": "1e-10"
      }
    }
  },
  {
    "function_call": {
      "name": "bayesian_ridge_regression",
      "arguments": {
        "alpha_1": "1e-6",
        "alpha_2": "1e-6"
      }
    }
  },
  {
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "3",
        "features": "feature1,feature2"
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "random_forest",
        "features": "featureA,featureB"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "skewed_columns",
        "lmbda": "auto"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3",
        "hue": "class"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_boxplot",
      "arguments": {
        "feature": "income",
        "category": "education_level"
      }
    }
  },
  {
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": "[10, 25, 50]"
      }
    }
  },
  {
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "numeric_features"
      }
    }
  },
  {
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3",
        "stratify": "target_class"
      }
    }
  },
  {
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "['category1', 'category2']"
      }
    }
  },
  {
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "['categorical_feature']"
      }
    }
  },
  {
    "function_call": {
      "name": "logistic_regression",
      "arguments": {
        "penalty": "l2",
        "C": "1.0"
      }
    }
  },
  {
    "function_call": {
      "name": "svc",
      "arguments": {
        "kernel": "linear",
        "C": "1.0"
      }
    }
  },
  {
    "function_call": {
      "name": "linear_regression",
      "arguments": {
        "fit_intercept": "True"
      }
    }
  },
  {
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "n_components": "2"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2",
        "gap": "1"
      }
    }
  },
  {
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "age,income",
        "degree": "2"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureX', 'featureY')"
      }
    }
  },
  {
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "random_forest",
        "test_set": "test_data"
      }
    }
  },
  {
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svm",
        "folds": "10",
        "scoring": "accuracy"
      }
    }
  },
  {
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "knn",
        "y_true": "true_labels",
        "y_pred": "predicted_labels"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "xgb_classifier",
        "top_n": "10"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age",
        "bins": "20"
      }
    }
  },
  {
    "function_call": {
      "name": "data_enrichment_api_integration",
      "arguments": {
        "api_endpoint": "https://api.example.com/data",
        "fields": "additional_fields"
      }
    }
  },
  {
    "function_call": {
      "name": "data_cleaning_null_value_imputation_mean",
      "arguments": {
        "columns": "numeric_features"
      }
    }
  },
  {
    "function_call": {
      "name": "feature_selection_chi_square",
      "arguments": {
        "num_features": "10"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_min_max_per_feature",
      "arguments": {
        "columns": "all_numeric"
      }
    }
  },
  {
    "function_call": {
      "name": "data_discretization_equal_width",
      "arguments": {
        "columns": "continuous_cols",
        "bins": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "data_balance_undersampling",
      "arguments": {
        "minority_class": "rare_class"
      }
    }
  },
  {
    "function_call": {
      "name": "data_augmentation_image_crop",
      "arguments": {
        "image_column": "image_data",
        "crop_percentage": "0.1"
      }
    }
  },
  {
    "function_call": {
      "name": "data_split_custom",
      "arguments": {
        "train_fraction": "0.7",
        "random_state": "42"
      }
    }
  },
  {
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "random_forest",
        "param_grid": {
          "n_estimators": [
            100,
            200
          ],
          "max_depth": [
            "None",
            10,
            20
          ]
        }
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretability_lime",
      "arguments": {
        "model": "lr",
        "instance": "specific_instance"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_log_transform",
      "arguments": {
        "columns": "positive_numeric_features"
      }
    }
  },
  {
    "function_call": {
      "name": "data_discretization_kmeans_bins",
      "arguments": {
        "columns": "continuous_features",
        "num_bins": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_scatter_matrix",
      "arguments": {
        "features": "feature1,feature2,feature3"
      }
    }
  },
  {
    "function_call": {
      "name": "data_balance_over_sampling",
      "arguments": {
        "majority_class": "common_class"
      }
    }
  },
  {
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.1",
        "l1_ratio": "0.5"
      }
    }
  },
  {
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.01"
      }
    }
  },
  {
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "1.0"
      }
    }
  },
  {
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF",
        "alpha": "1e-6"
      }
    }
  },
  {
    "function_call": {
      "name": "bayesian_ridge_regression",
      "arguments": {
        "alpha_1": "1e-6",
        "alpha_2": "1e-6"
      }
    }
  },
  {
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "2",
        "features": "feature1,feature2"
      }
    }
  },
  {
    "function_call": {
      "name": "random_forest_regression",
      "arguments": {
        "n_estimators": "100",
        "max_depth": "None"
      }
    }
  },
  {
    "function_call": {
      "name": "gradient_boosting_regression",
      "arguments": {
        "n_estimators": "100",
        "learning_rate": "0.1"
      }
    }
  },
  {
    "function_call": {
      "name": "model_interpretability_permutation_importance",
      "arguments": {
        "model": "random_forest",
        "data": "validation_data"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_boxcox_optimized",
      "arguments": {
        "columns": "skewed_features",
        "optimize": "True"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_density_plot",
      "arguments": {
        "feature": "income"
      }
    }
  },
  {
    "function_call": {
      "name": "data_cleaning_outlier_detection_zscore",
      "arguments": {
        "threshold": "3"
      }
    }
  },
  {
    "function_call": {
      "name": "data_augmentation_synthetic_samples",
      "arguments": {
        "method": "SMOTE",
        "features": "all_features"
      }
    }
  },
  {
    "function_call": {
      "name": "time_series_exponential_smoothing_seasonal",
      "arguments": {
        "seasonal": "multiplicative",
        "trend": "add",
        "seasonal_periods": "12"
      }
    }
  },
  {
    "function_call": {
      "name": "ensemble_nearest_neighbors_regression",
      "arguments": {
        "neighbors": "5"
      }
    }
  },
  {
    "function_call": {
      "name": "data_visualization_correlation_heatmap",
      "arguments": {
        "correlation_method": "pearson"
      }
    }
  },
  {
    "function_call": {
      "name": "data_enrichment_web_scraping",
      "arguments": {
        "urls": "list_of_urls",
        "data_columns": "to_enrich"
      }
    }
  },
  {
    "function_call": {
      "name": "data_sampling_stratified",
      "arguments": {
        "fraction": "0.5",
        "stratify_by": "class"
      }
    }
  },
  {
    "function_call": {
      "name": "data_transformation_standard_scaler_selected",
      "arguments": {
        "columns": "selected_numeric_features"
      }
    }
  },
  {
    "function_call": {
      "name": "data_discretization_quantile_bins_adaptive",
      "arguments": {
        "columns": "continuous_cols",
        "bins": "auto"
      }
    }
  },
  {
    "function_call": {
      "name": "data_balance_smoteENN",
      "arguments": {
        "minority_class": "rare_class"
      }
    }
  },
  {
    "function_call": {
      "name": "model_evaluation_roc_curve",
      "arguments": {
        "model": "binary_classifier"
      }
    }
  },
  {
    "function_call": {
      "name": "data_preprocessing_pipeline_custom",
      "arguments": {
        "steps": "[standardize, one_hot_encode]"
      },
      "pipeline_order": "custom"
    }
  },
  {
    "instruction": "Get an overview of the data.",
    "function_call": {
      "name": "data_description",
      "arguments": {}
    }
  },
  {
    "instruction": "Show the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete the 'unnecessary_column' from the dataset.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_column"
      }
    }
  },
  {
    "instruction": "Delete rows indexed at 0, 5, and 10.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          "0",
          "5",
          "10"
        ]
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the data into 80% for training and 20% for testing.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode categorical column 'category' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'gender' and 'location' columns.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "gender,location"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an SVM model for classification.",
    "function_call": {
      "name": "svc",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a linear regression model.",
    "function_call": {
      "name": "linear_regression",
      "arguments": {}
    }
  },
  {
    "instruction": "Draw a correlation matrix for the dataset.",
    "function_call": {
      "name": "correlation_matrix",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a neural network for classification tasks.",
    "function_call": {
      "name": "neural_network_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an XGB classifier.",
    "function_call": {
      "name": "xgb_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier",
      "arguments": {}
    }
  },
  {
    "instruction": "Extract the task and target as 'classification' from the data.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Get the overview of the data.",
    "function_call": {
      "name": "data_description"
    }
  },
  {
    "instruction": "Show the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete the 'unnecessary_column' from the data.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_column"
      }
    }
  },
  {
    "instruction": "Delete rows at indices 0, 1, and 2.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": [
          "0,1,2"
        ]
      }
    }
  },
  {
    "instruction": "Standardize the 'age' and 'income' columns.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "age,income"
      }
    }
  },
  {
    "instruction": "Split the dataset into 80% train and 20% test datasets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode categorical column 'species' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "species"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'color' column.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "color"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression"
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) model for classification.",
    "function_call": {
      "name": "svc"
    }
  },
  {
    "instruction": "Train a linear regression model for predicting 'price'.",
    "function_call": {
      "name": "linear_regression"
    }
  },
  {
    "instruction": "Draw a correlation matrix for feature analysis.",
    "function_call": {
      "name": "correlation_matrix"
    }
  },
  {
    "instruction": "Train a neural network for classification.",
    "function_call": {
      "name": "neural_network_classifier"
    }
  },
  {
    "instruction": "Train a decision tree for classification.",
    "function_call": {
      "name": "decision_tree_classifier"
    }
  },
  {
    "instruction": "Train a random forest for classification.",
    "function_call": {
      "name": "random_forest_classifier"
    }
  },
  {
    "instruction": "Train an XGB classifier.",
    "function_call": {
      "name": "xgb_classifier"
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier"
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier"
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier"
    }
  },
  {
    "instruction": "Extract task and target as 'classification' and 'target_column'.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Select top 5 important features based on mutual information.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Normalize 'height' and 'weight' columns.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "height,weight"
      }
    }
  },
  {
    "instruction": "Impute missing values in 'age' column using mean strategy.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean",
        "value": ""
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce dimensions to 2.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data with a test size of 0.2.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureA','featureB')"
      }
    }
  },
  {
    "instruction": "Evaluate the accuracy of a trained logistic regression model.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "logistic_regression_model"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the SVM model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "svc",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Generate a confusion matrix plot for the decision tree model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the random forest model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'salary' column using IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Load the saved logistic regression model.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "logistic_regression_model.pkl"
      }
    }
  },
  {
    "instruction": "Check for class imbalance in the 'target' column.",
    "function_call": {
      "name": "data_balance_check"
    }
  },
  {
    "instruction": "Scale 'feature1' and 'feature2' using Min-Max Scaling.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Treat detected outliers in 'age' column by capping.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "99"
      }
    }
  },
  {
    "instruction": "Sample 80% of the data for reduction.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'feature1' and 'feature2' to create 'combined_feature'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "feature1+feature2"
      }
    }
  },
  {
    "instruction": "Eliminate features using backward elimination.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "accuracy"
      }
    }
  },
  {
    "instruction": "Forecast sales for the next 6 months using ARIMA.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "arima",
        "horizon": "6"
      }
    }
  },
  {
    "instruction": "Interpret the predictions of the logistic regression model for instance '123'.",
    "function_call": {
      "name": "model_interpretation",
      "arguments": {
        "model": "logistic_regression",
        "instance_id": "123"
      }
    }
  },
  {
    "instruction": "Anonymize the 'personal_info' column to protect privacy.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize 'age' into 5 equal-width bins.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_width",
        "bins": "5",
        "columns": "age"
      }
    }
  },
  {
    "instruction": "Increase dataset size by 20% with rotation augmentation.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "rotation",
        "augmentation_percentage": "20"
      }
    }
  },
  {
    "instruction": "Visualize the 'age' distribution with 10 bins.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age",
        "bins": "10"
      }
    }
  },
  {
    "instruction": "Plot pairwise relationships for 'feature1', 'feature2', and 'feature3' with hue 'category'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Analyze model complexity of the random forest.",
    "function_call": {
      "name": "model_complexity_analysis"
    }
  },
  {
    "instruction": "Apply logarithmic transformation to 'income' column.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "income"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'sales' column.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "sales"
      }
    }
  },
  {
    "instruction": "Select top 10 features using mutual information for regression.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "10"
      }
    }
  },
  {
    "instruction": "Select features using recursive feature elimination with the random forest.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "random_forest",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Train a random forest regression model with 100 estimators.",
    "function_call": {
      "name": "random_forest_regression",
      "arguments": {
        "n_estimators": "100"
      }
    }
  },
  {
    "instruction": "Evaluate the random forest regression model using ROC AUC.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "random_forest_regression"
      }
    }
  },
  {
    "instruction": "Remove duplicate rows from the dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Transform text data using TF-IDF with 1000 features.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000"
      }
    }
  },
  {
    "instruction": "Split dataset into 5 folds for cross-validation.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Optimize hyperparameters of the logistic regression model using grid search.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "logistic_regression",
        "param_grid": {
          "C": [
            0.001,
            0.01,
            0.1,
            1,
            10,
            100,
            1000
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate recall score for the trained SVM model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "svm"
      }
    }
  },
  {
    "instruction": "Calculate precision score for the decision tree model.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "decision_tree"
      }
    }
  },
  {
    "instruction": "Calculate mean squared error for the linear regression model.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate R-squared for the random forest regression model.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "random_forest_regression"
      }
    }
  },
  {
    "instruction": "Calculate mean absolute error for the regression model.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "regression_model"
      }
    }
  },
  {
    "instruction": "Plot residuals for the linear regression model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression",
        "predictions": "predicted_values",
        "actuals": "actual_values"
      }
    }
  },
  {
    "instruction": "Calculate prediction intervals for the random forest regression.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "random_forest_regression",
        "data": "new_data",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize regression coefficients for the linear regression model.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Assess multicollinearity using VIF for 'feature1', 'feature2', 'feature3'.",
    "function_call": {
      "name": "regression_multicollinearity_vif",
      "arguments": {
        "data": "[feature1, feature2, feature3]"
      }
    }
  },
  {
    "instruction": "Train an Elastic Net Regression model with alpha=0.1 and l1_ratio=0.5.",
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.1",
        "l1_ratio": "0.5"
      }
    }
  },
  {
    "instruction": "Train a Lasso Regression model with alpha=0.01.",
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.01"
      }
    }
  },
  {
    "instruction": "Train a Ridge Regression model with alpha=1.0.",
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "1.0"
      }
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression model with 'linear' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Process Regression model with 'RBF' kernel.",
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF"
      }
    }
  },
  {
    "instruction": "Train a Bayesian Ridge Regression model with alpha_1=1e-6, alpha_2=1e-6.",
    "function_call": {
      "name": "bayesian_ridge_regression",
      "arguments": {
        "alpha_1": "1e-6",
        "alpha_2": "1e-6"
      }
    }
  },
  {
    "instruction": "Fit a polynomial regression model of degree 3.",
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "3"
      }
    }
  },
  {
    "instruction": "Visualize partial dependence for 'featureX' and 'featureY' in the random forest model.",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "random_forest",
        "features": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Apply exponential smoothing with additive trend and multiplicative seasonality.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "trend": "add",
        "seasonal": "mul"
      }
    }
  },
  {
    "instruction": "Perform Gaussian Mixture clustering with 3 components.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "3"
      }
    }
  },
  {
    "instruction": "Use random forest for clustering with 5 clusters.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "5"
      }
    }
  },
  {
    "instruction": "Combine three classifiers using voting.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['clf1', 'clf2', 'clf3']",
        "voting": "hard"
      }
    }
  },
  {
    "instruction": "Optimize model with Stochastic Gradient Descent (SGD) using 'hinge' loss.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "constant",
        "loss": "hinge"
      }
    }
  },
  {
    "instruction": "Use Adam optimizer with a learning rate of 0.001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Optimize with RMSprop, setting rho to 0.95.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "rho": "0.95"
      }
    }
  },
  {
    "instruction": "Apply Adagrad with an initial learning rate of 0.1.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.1"
      }
    }
  },
  {
    "instruction": "Use Nesterov optimizer with a learning rate of 0.01.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Optimize with Limited-memory BFGS.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Use basic Gradient Descent with a learning rate of 0.05.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.05"
      }
    }
  },
  {
    "instruction": "Analyze the 'age' distribution for different categories in 'gender'.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "age",
        "bins": "10",
        "hue": "gender"
      }
    }
  },
  {
    "instruction": "Create a pairplot for numeric features 'feature1', 'feature2', 'feature3' with 'category' hue.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Split the dataset into training and testing sets with a 70:30 ratio.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.3"
      }
    }
  },
  {
    "instruction": "Delete the 'unnecessary_col1', 'unnecessary_col2' columns from the dataset.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "unnecessary_col1,unnecessary_col2"
      }
    }
  },
  {
    "instruction": "Standardize the 'features_to_normalize' column.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "features_to_normalize"
      }
    }
  },
  {
    "instruction": "Encode 'categorical_column' using ordinal encoding.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "categorical_column"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'categorical_features' columns.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "categorical_features"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model with 'class_label' as target.",
    "function_call": {
      "name": "logistic_regression"
    }
  },
  {
    "instruction": "Train a support vector machine (SVM) for classification.",
    "function_call": {
      "name": "svc"
    }
  },
  {
    "instruction": "Fit a linear regression model to predict 'target_variable'.",
    "function_call": {
      "name": "linear_regression"
    }
  },
  {
    "instruction": "Draw a correlation matrix to examine feature relationships.",
    "function_call": {
      "name": "correlation_matrix"
    }
  },
  {
    "instruction": "Train a neural network for a classification task.",
    "function_call": {
      "name": "neural_network_classifier"
    }
  },
  {
    "instruction": "Build a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier"
    }
  },
  {
    "instruction": "Train a random forest for a classification problem.",
    "function_call": {
      "name": "random_forest_classifier"
    }
  },
  {
    "instruction": "Fit an XGBoost model for classification.",
    "function_call": {
      "name": "xgb_classifier"
    }
  },
  {
    "instruction": "Train a bagging classifier ensemble.",
    "function_call": {
      "name": "bagging_classifier"
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier"
    }
  },
  {
    "instruction": "Fit a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier"
    }
  },
  {
    "instruction": "Identify task and target as regression with 'target_field'.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "regression",
        "target": "target_field"
      }
    }
  },
  {
    "instruction": "Select top 10 features based on mutual information for a regression task.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "10"
      }
    }
  },
  {
    "instruction": "Normalize 'numerical_features' columns.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "numerical_features"
      }
    }
  },
  {
    "instruction": "Impute missing values in 'age' column using the median.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "median",
        "value": ""
      }
    }
  },
  {
    "instruction": "Reduce data dimensions using PCA to retain 95% variance.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "0.95"
      }
    }
  },
  {
    "instruction": "Split time series data with a 20% test set respecting time order.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features 'featureA_squared', 'featureB_squared'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "featureA,featureB",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureX' and 'featureY'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "('featureX','featureY')"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of the trained SVM model on test data.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "svm_model"
      }
    }
  },
  {
    "instruction": "Perform 10-fold cross-validation on the random forest model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "random_forest",
        "folds": "10"
      }
    }
  },
  {
    "instruction": "Plot the confusion matrix for the decision tree classifier.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the random forest model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'featureZ' using IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Load the saved random forest model.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "random_forest_model.pkl"
      }
    }
  },
  {
    "instruction": "Check if 'target' has class imbalance.",
    "function_call": {
      "name": "data_balance_check"
    }
  },
  {
    "instruction": "Min-Max scale 'price', 'volume' columns.",
    "function_call": {
      "name": "feature_scaling_minmax",
      "arguments": {
        "columns": "price,volume"
      }
    }
  },
  {
    "instruction": "Treat detected outliers in 'featureX' by setting them to the mean.",
    "function_call": {
      "name": "data_outlier_treatment",
      "arguments": {
        "treatment": "capping",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Randomly sample 80% of the dataset for training.",
    "function_call": {
      "name": "data_sampling",
      "arguments": {
        "method": "random_sampling",
        "fraction": "0.8"
      }
    }
  },
  {
    "instruction": "Combine 'featureA' and 'featureB' into 'AB_feature'.",
    "function_call": {
      "name": "feature_combination",
      "arguments": {
        "combinations": "featureA+featureB"
      }
    }
  },
  {
    "instruction": "Eliminate features using backward elimination until 5 remain.",
    "function_call": {
      "name": "feature_elimination",
      "arguments": {
        "method": "backward_elimination",
        "scoring": "roc_auc",
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Forecast sales for the next quarter using LSTM.",
    "function_call": {
      "name": "time_series_forecasting",
      "arguments": {
        "model": "lstm",
        "horizon": "3"
      }
    }
  },
  {
    "instruction": "Interpret the logistic regression model's predictions.",
    "function_call": {
      "name": "model_interpretability_shap_values",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Anonymize 'personal_data' to preserve privacy.",
    "function_call": {
      "name": "data_anonymization",
      "arguments": {
        "method": "k_anonymity"
      }
    }
  },
  {
    "instruction": "Discretize 'age' into 5 bins using equal frequency.",
    "function_call": {
      "name": "data_discretization",
      "arguments": {
        "method": "equal_frequency",
        "bins": "5",
        "columns": "age"
      }
    }
  },
  {
    "instruction": "Increase dataset size by 20% with horizontal flips for image data.",
    "function_call": {
      "name": "data_augmentation",
      "arguments": {
        "method": "horizontal_flip",
        "augmentation_percentage": "20"
      }
    }
  },
  {
    "instruction": "Visualize 'featureX' distribution with 20 bins.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "featureX",
        "bins": "20"
      }
    }
  },
  {
    "instruction": "Plot pairwise relationships of 'numeric_features' with hue 'category'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "numeric_features",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Analyze the complexity of the random forest model.",
    "function_call": {
      "name": "model_complexity_analysis"
    }
  },
  {
    "instruction": "Log-transform 'skewed_feature' to improve normality.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "skewed_feature"
      }
    }
  },
  {
    "instruction": "Apply Box-Cox transformation to 'featureY'.",
    "function_call": {
      "name": "data_transformation_boxcox",
      "arguments": {
        "columns": "featureY"
      }
    }
  },
  {
    "instruction": "Select top 5 features for regression using mutual information.",
    "function_call": {
      "name": "feature_selection_mutual_info_regression",
      "arguments": {
        "num_features": "5"
      }
    }
  },
  {
    "instruction": "Use RFE to select 3 best features for the linear regression model.",
    "function_call": {
      "name": "feature_selection_rfe",
      "arguments": {
        "model": "linear_regression",
        "num_features": "3"
      }
    }
  },
  {
    "instruction": "Train a random forest regression for predicting 'target_value'.",
    "function_call": {
      "name": "random_forest_regression",
      "arguments": {
        "n_estimators": "100"
      }
    }
  },
  {
    "instruction": "Calculate ROC AUC for the logistic regression model.",
    "function_call": {
      "name": "model_evaluation_roc_auc",
      "arguments": {
        "model": "logistic_regression"
      }
    }
  },
  {
    "instruction": "Remove duplicates from the dataset.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal"
    }
  },
  {
    "instruction": "Extract TF-IDF features from 'text_column'.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "5000"
      }
    }
  },
  {
    "instruction": "Cross-validate the KNN model with 5 folds.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Grid search hyperparameters for the SVM model.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "svm",
        "param_grid": {
          "C": [
            0.1,
            1,
            10,
            100
          ],
          "kernel": [
            "linear",
            "rbf"
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate recall for the random forest model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "random_forest"
      }
    }
  },
  {
    "instruction": "Calculate precision for the decision tree model.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "decision_tree"
      }
    }
  },
  {
    "instruction": "Calculate MSE for the linear regression model.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate R² score for the elastic net model.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "elastic_net_regression"
      }
    }
  },
  {
    "instruction": "Calculate MAE for the gradient boosting model.",
    "function_call": {
      "name": "mean_absolute_error",
      "arguments": {
        "model": "gradient_boosting_regression"
      }
    }
  },
  {
    "instruction": "Analyze residuals for the linear regression model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression",
        "predictions": "predicted",
        "actuals": "actual"
      }
    }
  },
  {
    "instruction": "Create prediction intervals for the random forest regression.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "random_forest_regression",
        "data": "test_set",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize regression coefficients for the linear model.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Assess multicollinearity among 'feature1', 'feature2', 'feature3'.",
    "function_call": {
      "name": "regression_multicollinearity_vif",
      "arguments": {
        "data": "[feature1, feature2, feature3]"
      }
    }
  },
  {
    "instruction": "Train an Elastic Net model with alpha=0.05 and l1_ratio=0.7.",
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.05",
        "l1_ratio": "0.7"
      }
    }
  },
  {
    "instruction": "Fit a Lasso Regression with a high alpha for feature selection.",
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "10"
      }
    }
  },
  {
    "instruction": "Train a Ridge Regression model with a moderate alpha.",
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "2"
      }
    }
  },
  {
    "instruction": "Use Kernel Ridge Regression with a 'poly' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "kernel": "poly",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Train a Gaussian Process Regression model with an 'RBF' kernel.",
    "function_call": {
      "name": "gaussian_process_regression",
      "arguments": {
        "kernel": "RBF"
      }
    }
  },
  {
    "instruction": "Fit a Bayesian Ridge Regression model with default settings.",
    "function_call": {
      "name": "bayesian_ridge_regression"
    }
  },
  {
    "instruction": "Create a polynomial regression model of degree 2.",
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Visualize feature importance with partial dependence for 'feature_imp'",
    "function_call": {
      "name": "model_interpretability_partial_dependence",
      "arguments": {
        "model": "random_forest",
        "features": "feature_imp"
      }
    }
  },
  {
    "instruction": "Forecast sales with exponential smoothing and seasonal adjustment.",
    "function_call": {
      "name": "time_series_exponential_smoothing",
      "arguments": {
        "model": "add",
        "seasonal": "mul"
      }
    }
  },
  {
    "instruction": "Cluster data using Gaussian Mixture with 4 clusters.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Cluster data with Random Forest, forming 3 clusters.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "100",
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Combine models with voting classifier.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['clf1', 'clf2', 'clf3']",
        "voting": "hard"
      }
    }
  },
  {
    "instruction": "Optimize with SGD using 'log' loss for binary classification.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "optimal",
        "loss": "log"
      }
    }
  },
  {
    "instruction": "Use Adam optimizer with a learning rate of 0.0001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.0001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Optimize with RMSprop for better convergence.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Apply Adagrad for adaptive learning rates.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Use Nesterov's momentum for faster convergence.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Optimize with L-BFGS for precise local optima.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "100"
      }
    }
  },
  {
    "instruction": "Use basic Gradient Descent for simple optimization.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.05"
      }
    }
  },
  {
    "instruction": "Display general information about the dataset.",
    "function_call": {
      "name": "data_description"
    }
  },
  {
    "instruction": "Show the first 10 rows of the dataset.",
    "function_call": {
      "name": "show_data_head",
      "arguments": {
        "row": "10"
      }
    }
  },
  {
    "instruction": "Delete columns named 'unnecessary_col1' and 'unnecessary_col2'.",
    "function_call": {
      "name": "delete_columns",
      "arguments": {
        "columns": "['unnecessary_col1', 'unnecessary_col2']"
      }
    }
  },
  {
    "instruction": "Delete rows at indices 0, 1, and 2.",
    "function_call": {
      "name": "delete_rows",
      "arguments": {
        "row_indices": "[0, 1, 2]"
      }
    }
  },
  {
    "instruction": "Standardize columns 'feature1' and 'feature2'.",
    "function_call": {
      "name": "standardization",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Split data into 80% train and 20% test sets.",
    "function_call": {
      "name": "datasets_split",
      "arguments": {
        "test_ratio": "0.2"
      }
    }
  },
  {
    "instruction": "Encode 'category' column as ordinal numbers.",
    "function_call": {
      "name": "ordinal_encoding",
      "arguments": {
        "columns": "category"
      }
    }
  },
  {
    "instruction": "Apply one-hot encoding to 'color' column.",
    "function_call": {
      "name": "one_hot_encoding",
      "arguments": {
        "columns": "color"
      }
    }
  },
  {
    "instruction": "Train a logistic regression model.",
    "function_call": {
      "name": "logistic_regression"
    }
  },
  {
    "instruction": "Train a support vector machine for classification.",
    "function_call": {
      "name": "svc"
    }
  },
  {
    "instruction": "Train a linear regression model.",
    "function_call": {
      "name": "linear_regression"
    }
  },
  {
    "instruction": "Draw a correlation matrix for feature analysis.",
    "function_call": {
      "name": "correlation_matrix"
    }
  },
  {
    "instruction": "Train a neural network classifier.",
    "function_call": {
      "name": "neural_network_classifier"
    }
  },
  {
    "instruction": "Train a decision tree classifier.",
    "function_call": {
      "name": "decision_tree_classifier"
    }
  },
  {
    "instruction": "Train a random forest classifier.",
    "function_call": {
      "name": "random_forest_classifier"
    }
  },
  {
    "instruction": "Train an XGBoost classifier.",
    "function_call": {
      "name": "xgb_classifier"
    }
  },
  {
    "instruction": "Train a bagging classifier.",
    "function_call": {
      "name": "bagging_classifier"
    }
  },
  {
    "instruction": "Train an AdaBoost classifier.",
    "function_call": {
      "name": "ada_boost_classifier"
    }
  },
  {
    "instruction": "Train a gradient boosting classifier.",
    "function_call": {
      "name": "gradient_boosting_classifier"
    }
  },
  {
    "instruction": "Identify task and target as 'classification' for 'target_column'.",
    "function_call": {
      "name": "specify_task_and_target",
      "arguments": {
        "task": "classification",
        "target": "target_column"
      }
    }
  },
  {
    "instruction": "Select top 5 important features based on mutual information.",
    "function_call": {
      "name": "feature_selection",
      "arguments": {
        "method": "mutual_info",
        "k": "5"
      }
    }
  },
  {
    "instruction": "Normalize 'feature1' and 'feature2' columns.",
    "function_call": {
      "name": "data_normalization",
      "arguments": {
        "columns": "feature1,feature2"
      }
    }
  },
  {
    "instruction": "Handle missing values in 'age' column using mean strategy.",
    "function_call": {
      "name": "impute_missing_values",
      "arguments": {
        "strategy": "mean",
        "value": ""
      }
    }
  },
  {
    "instruction": "Perform PCA to reduce data to 2 principal components.",
    "function_call": {
      "name": "principal_component_analysis",
      "arguments": {
        "components": "2"
      }
    }
  },
  {
    "instruction": "Split time series data with 20% for testing.",
    "function_call": {
      "name": "time_series_split",
      "arguments": {
        "test_size": "0.2"
      }
    }
  },
  {
    "instruction": "Create quadratic features from 'feature1' and 'feature2'.",
    "function_call": {
      "name": "create_features_by_polynomial",
      "arguments": {
        "features": "feature1,feature2",
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Create interaction terms between 'featureA' and 'featureB'.",
    "function_call": {
      "name": "feature_interactions",
      "arguments": {
        "feature_pairs": "['(featureA,featureB)']"
      }
    }
  },
  {
    "instruction": "Evaluate accuracy of a trained model on test data.",
    "function_call": {
      "name": "train_test_accuracy",
      "arguments": {
        "model": "trained_model"
      }
    }
  },
  {
    "instruction": "Perform 5-fold cross-validation on the logistic regression model.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "logistic_regression",
        "folds": "5"
      }
    }
  },
  {
    "instruction": "Generate a confusion matrix for the decision tree model.",
    "function_call": {
      "name": "confusion_matrix_plot",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Extract feature importances from the random forest model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in 'income' column using IQR method.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "iqr",
        "threshold": "1.5"
      }
    }
  },
  {
    "instruction": "Load a saved model named 'my_model.pkl'.",
    "function_call": {
      "name": "load_model",
      "arguments": {
        "filename": "my_model.pkl"
      }
    }
  },
  {
    "instruction": "Check class balance for the 'target' column.",
    "function_call": {
      "name": "data_balance_check"
    }
  },
  {
    "instruction": "Transform 'text_data' column using TF-IDF.",
    "function_call": {
      "name": "feature_extraction_text_tfidf",
      "arguments": {
        "max_features": "1000",
        "columns": "text_data"
      }
    }
  },
  {
    "instruction": "Split data into 10 folds for cross-validation.",
    "function_call": {
      "name": "data_split_cross_validation",
      "arguments": {
        "folds": "10"
      }
    }
  },
  {
    "instruction": "Tune hyperparameters of the random forest using grid search.",
    "function_call": {
      "name": "model_tuning_grid_search",
      "arguments": {
        "model": "random_forest",
        "param_grid": {
          "n_estimators": [
            10,
            50,
            100
          ],
          "max_depth": [
            "None",
            10,
            50
          ]
        }
      }
    }
  },
  {
    "instruction": "Calculate recall score for the trained SVM model.",
    "function_call": {
      "name": "recall_score",
      "arguments": {
        "model": "svm"
      }
    }
  },
  {
    "instruction": "Calculate mean squared error for the linear regression model.",
    "function_call": {
      "name": "mean_squared_error",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Create a lift chart for the random forest model.",
    "function_call": {
      "name": "model_evaluation_lift_chart",
      "arguments": {
        "model": "random_forest_classifier",
        "bins": "10"
      }
    }
  },
  {
    "instruction": "Calculate precision score for the decision tree.",
    "function_call": {
      "name": "precision_score",
      "arguments": {
        "model": "decision_tree_classifier"
      }
    }
  },
  {
    "instruction": "Visualize residuals for the linear regression model.",
    "function_call": {
      "name": "regression_residual_analysis",
      "arguments": {
        "model": "linear_regression",
        "predictions": "predicted_values",
        "actuals": "actual_values"
      }
    }
  },
  {
    "instruction": "Calculate R-squared for the gradient boosting model.",
    "function_call": {
      "name": "r2_score",
      "arguments": {
        "model": "gradient_boosting_classifier"
      }
    }
  },
  {
    "instruction": "Create prediction intervals for the random forest regression.",
    "function_call": {
      "name": "regression_prediction_interval",
      "arguments": {
        "model": "random_forest_regression",
        "data": "new_data",
        "confidence_level": "0.95"
      }
    }
  },
  {
    "instruction": "Summarize regression coefficients for the linear model.",
    "function_call": {
      "name": "regression_coefs_summary",
      "arguments": {
        "model": "linear_regression"
      }
    }
  },
  {
    "instruction": "Calculate the Variance Inflation Factor for 'feature_set'.",
    "function_call": {
      "name": "regression_multicollinearity_vif",
      "arguments": {
        "data": "[feature_set]"
      }
    }
  },
  {
    "instruction": "Train an Elastic Net Regression with alpha=0.1.",
    "function_call": {
      "name": "elastic_net_regression",
      "arguments": {
        "alpha": "0.1"
      }
    }
  },
  {
    "instruction": "Train a Lasso Regression with alpha=0.05.",
    "function_call": {
      "name": "lasso_regression",
      "arguments": {
        "alpha": "0.05"
      }
    }
  },
  {
    "instruction": "Train a Ridge Regression with alpha=1.",
    "function_call": {
      "name": "ridge_regression",
      "arguments": {
        "alpha": "1"
      }
    }
  },
  {
    "instruction": "Train a Kernel Ridge Regression with 'linear' kernel.",
    "function_call": {
      "name": "kernel_ridge_regression",
      "arguments": {
        "kernel": "linear"
      }
    }
  },
  {
    "instruction": "Fit a polynomial regression of degree 2.",
    "function_call": {
      "name": "polynomial_regression",
      "arguments": {
        "degree": "2"
      }
    }
  },
  {
    "instruction": "Visualize the distribution of 'featureX' with 20 bins.",
    "function_call": {
      "name": "data_visualization_histogram",
      "arguments": {
        "feature": "featureX",
        "bins": "20"
      }
    }
  },
  {
    "instruction": "Plot pairwise relationships of 'featureA', 'featureB', 'featureC'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "featureA,featureB,featureC",
        "hue": "category"
      }
    }
  },
  {
    "instruction": "Analyze model complexity of the random forest.",
    "function_call": {
      "name": "model_complexity_analysis",
      "arguments": {
        "model": "random_forest_classifier"
      }
    }
  },
  {
    "instruction": "Apply logarithmic transformation to 'sales' column.",
    "function_call": {
      "name": "data_transformation_log",
      "arguments": {
        "columns": "sales"
      }
    }
  },
  {
    "instruction": "Apply Min-Max Scaling to 'featureX' and 'featureY'.",
    "function_call": {
      "name": "data_transformation_minmax",
      "arguments": {
        "columns": "featureX,featureY"
      }
    }
  },
  {
    "instruction": "Use Naive Bayes for classification.",
    "function_call": {
      "name": "naive_bayes_classifier",
      "arguments": {
        "algo": "multinomial"
      }
    }
  },
  {
    "instruction": "Perform spectral clustering with 3 clusters.",
    "function_call": {
      "name": "spectral_clustering",
      "arguments": {
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Fit a Gaussian Mixture Model with 4 clusters.",
    "function_call": {
      "name": "gaussian_mixture_model",
      "arguments": {
        "n_components": "4"
      }
    }
  },
  {
    "instruction": "Cluster data using Random Forest with 50 estimators.",
    "function_call": {
      "name": "random_forest_cluster",
      "arguments": {
        "n_estimators": "50",
        "n_clusters": "3"
      }
    }
  },
  {
    "instruction": "Combine models using voting.",
    "function_call": {
      "name": "ensemble_voting_classifier",
      "arguments": {
        "classifiers": "['model1', 'model2', 'model3']",
        "voting": "hard"
      }
    }
  },
  {
    "instruction": "Use Stochastic Gradient Descent with 'log' loss.",
    "function_call": {
      "name": "sgd_optimizer",
      "arguments": {
        "learning_rate": "optimal",
        "loss": "log"
      }
    }
  },
  {
    "instruction": "Optimize with Adam optimizer, learning rate 0.001.",
    "function_call": {
      "name": "adam_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "beta_1": "0.9",
        "beta_2": "0.999"
      }
    }
  },
  {
    "instruction": "Use RMSprop for optimization.",
    "function_call": {
      "name": "rmsprop_optimizer",
      "arguments": {
        "learning_rate": "0.001",
        "rho": "0.9"
      }
    }
  },
  {
    "instruction": "Apply Adagrad for optimization.",
    "function_call": {
      "name": "adagrad_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Use Nesterov's momentum for optimization.",
    "function_call": {
      "name": "nesterov_optimizer",
      "arguments": {
        "learning_rate": "0.01"
      }
    }
  },
  {
    "instruction": "Employ L-BFGS for optimization.",
    "function_call": {
      "name": "lbfgs_optimizer",
      "arguments": {
        "max_iter": "1000"
      }
    }
  },
  {
    "instruction": "Use basic Gradient Descent with learning rate 0.001.",
    "function_call": {
      "name": "gradient_descent_optimizer",
      "arguments": {
        "learning_rate": "0.001"
      }
    }
  },
  {
    "instruction": "Visualize feature importance for the trained gradient boosting model.",
    "function_call": {
      "name": "feature_importance",
      "arguments": {
        "model": "gradient_boosting_classifier"
      }
    }
  },
  {
    "instruction": "Detect outliers in the 'price' column using Z-score method with a threshold of 3.",
    "function_call": {
      "name": "outlier_detection",
      "arguments": {
        "method": "zscore",
        "threshold": "3"
      }
    }
  },
  {
    "instruction": "Balance the 'target' column in the dataset using the 'SMOTE' technique.",
    "function_call": {
      "name": "data_cleaning_duplicate_removal",
      "arguments": {
        "task": "imbalance_handling",
        "method": "SMOTE",
        "target": "target"
      }
    }
  },
  {
    "instruction": "Create a scatter plot matrix for 'feature1', 'feature2', and 'feature3'.",
    "function_call": {
      "name": "data_visualization_pairplot",
      "arguments": {
        "features": "feature1,feature2,feature3"
      }
    }
  },
  {
    "instruction": "Save the trained neural network model as 'nn_model.pkl'.",
    "function_call": {
      "name": "save_model",
      "arguments": {
        "model": "neural_network_classifier",
        "filename": "nn_model.pkl"
      }
    }
  },
  {
    "instruction": "Evaluate the robustness of the logistic regression model using cross-validation with 10 folds.",
    "function_call": {
      "name": "cross_validation",
      "arguments": {
        "model": "logistic_regression",
        "folds": "10"
      }
    }
  }
]